{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./eztransfer_modelzoo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为环境变量做好准备\n",
    "import os\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_text = \"\"\"\n",
    "HOME=./eztransfer_modelzoo\n",
    "\"\"\"\n",
    "\n",
    "load_dotenv(stream=StringIO(env_text), override=True, verbose=True)\n",
    "os.environ.get(\"HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\code\\\\github\\\\EasyTransfer',\n",
       " 'd:\\\\code\\\\github\\\\EasyTransfer\\\\examples',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles\\\\vscode_datascience_helpers',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles\\\\lib\\\\python',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\python39.zip',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\DLLs',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2',\n",
       " '',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 让本地的 easytransfer 的优先级更高\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*********** tf.__version__ is 2.7.0 ******\n"
     ]
    }
   ],
   "source": [
    "# 导入 easytransfer, 并验证, 因为原始的没有 __version__ 这个参数\n",
    "import importlib\n",
    "import easytransfer as easytransfer\n",
    "importlib.reload(easytransfer)\n",
    "easytransfer.__version__\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ipykernel_launcher', '--ip=127.0.0.1', '--stdin=9018', '--control=9016', '--hb=9015', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"43401d51-c03b-4494-84da-34e48ffdd397\"', '--shell=9017', '--transport=\"tcp\"', '--iopub=9019', '--f=C:\\\\Users\\\\tzh\\\\AppData\\\\Local\\\\Temp\\\\tmp-31956Hwb5mLyK44gt.json']\n"
     ]
    }
   ],
   "source": [
    "# jupyter 特殊操作\n",
    "old_argv = sys.argv\n",
    "print(old_argv)\n",
    "sys.argv = old_argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easytransfer.model_zoo.modeling_bert import BertConfig, BertPreTrainedModel, MyBertPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<easytransfer.model_zoo.modeling_bert.BertConfig at 0x1d73d265dc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_config_path = \"D:/code/py_nlp_classify/model/bert/google-bert-base-zh/config.json\"\n",
    "bert_config = BertConfig.get(bert_config_path)\n",
    "bert_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<easytransfer.model_zoo.modeling_bert.BertPreTrainedModel at 0x1d73d29fdc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model = BertPreTrainedModel(bert_config)\n",
    "bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<easytransfer.model_zoo.modeling_bert.MyBertPreTrainedModel at 0x1d73d42f1c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bert_model = MyBertPreTrainedModel(bert_config)\n",
    "my_bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape [1, 512]\n",
      "<class 'tuple'>\n",
      "3\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(512, 21128)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 2)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "(1, 768)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(512, 21128), dtype=float32, numpy=\n",
       " array([[-0.4718424 ,  0.15066633,  0.11407417, ..., -0.3093407 ,\n",
       "         -0.6125126 , -0.71065575],\n",
       "        [-0.4718424 ,  0.15066633,  0.11407417, ..., -0.3093407 ,\n",
       "         -0.6125126 , -0.71065575],\n",
       "        [-0.4718424 ,  0.15066633,  0.11407417, ..., -0.3093407 ,\n",
       "         -0.6125126 , -0.71065575],\n",
       "        ...,\n",
       "        [-0.4718424 ,  0.15066633,  0.11407417, ..., -0.3093407 ,\n",
       "         -0.6125126 , -0.71065575],\n",
       "        [-0.4718424 ,  0.15066633,  0.11407417, ..., -0.3093407 ,\n",
       "         -0.6125126 , -0.71065575],\n",
       "        [-0.4718424 ,  0.15066633,  0.11407417, ..., -0.3093407 ,\n",
       "         -0.6125126 , -0.71065575]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[0.10771573, 0.11877879]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       " array([[-2.61349618e-01,  1.67544410e-01, -4.50660944e-01,\n",
       "         -4.07234311e-01,  2.75090694e-01, -6.27516150e-01,\n",
       "          2.78590143e-01, -5.12637831e-02,  4.92307805e-02,\n",
       "          6.19775772e-01, -2.71107078e-01, -3.31090778e-01,\n",
       "          7.20834374e-01,  7.72288322e-01, -2.65983701e-01,\n",
       "         -8.66163909e-01, -5.08993864e-01, -2.63873219e-01,\n",
       "         -3.17281485e-01, -6.34851038e-01, -1.13841228e-01,\n",
       "         -6.14200592e-01,  1.31001715e-02, -4.61650640e-01,\n",
       "          2.81306148e-01,  5.72409809e-01,  7.40465581e-01,\n",
       "         -7.02834785e-01, -7.48954713e-01,  1.59449980e-01,\n",
       "          3.36103588e-01,  2.32050464e-01, -7.23167211e-02,\n",
       "         -1.89213216e-01,  5.79334974e-01, -5.97434640e-01,\n",
       "         -4.15780663e-01,  6.72697842e-01, -7.07370520e-01,\n",
       "         -5.84326029e-01, -1.63933322e-01,  6.81464374e-01,\n",
       "         -1.71914607e-01,  8.20116997e-01,  1.80376723e-01,\n",
       "         -5.00080585e-01,  4.06055450e-01, -2.76706249e-01,\n",
       "          6.93727508e-02,  2.60048687e-01, -8.63983870e-01,\n",
       "         -1.02294616e-01, -1.71484634e-01, -1.30736828e-01,\n",
       "          5.45091808e-01, -4.54981267e-01, -5.55231690e-01,\n",
       "         -1.48856202e-02, -4.09094572e-01,  3.40989292e-01,\n",
       "         -3.00065763e-02,  3.77769768e-01,  6.69593751e-01,\n",
       "          5.05794659e-02, -2.47018069e-01,  4.61223483e-01,\n",
       "         -3.02117560e-02, -4.28685576e-01, -4.32592839e-01,\n",
       "          2.87835747e-01, -2.40029871e-01, -2.62944639e-01,\n",
       "         -4.04362410e-01, -5.20239592e-01,  1.50342077e-01,\n",
       "         -7.17206478e-01, -7.25031495e-01, -3.92095655e-01,\n",
       "          2.49123275e-01,  4.96594965e-01,  1.86942965e-01,\n",
       "          8.37975979e-01, -6.44105673e-01,  4.50430334e-01,\n",
       "          2.18628064e-01, -3.02455664e-01, -6.18290722e-01,\n",
       "         -1.09479129e-01,  1.60295442e-01,  3.42897892e-01,\n",
       "         -1.79069474e-01, -2.21409991e-01,  1.48022890e-01,\n",
       "         -2.80048847e-01,  3.34849298e-01, -5.84341325e-02,\n",
       "          5.05559802e-01, -1.79101035e-01, -4.67339724e-01,\n",
       "         -3.46986622e-01, -2.17490569e-01, -6.12112820e-01,\n",
       "          2.32104912e-01,  5.82373261e-01, -7.36131847e-01,\n",
       "          4.30372298e-01,  4.94612418e-02, -3.74321342e-01,\n",
       "         -5.67628145e-01, -6.84562564e-01,  6.26371009e-03,\n",
       "          7.05739856e-01, -2.97641784e-01, -9.16769505e-02,\n",
       "          6.10951185e-02, -6.03939444e-02, -2.98098803e-01,\n",
       "         -1.66552812e-01, -2.87890613e-01,  9.54110995e-02,\n",
       "          7.96032883e-03, -4.14245099e-01, -5.44734478e-01,\n",
       "         -2.75893718e-01,  5.31701922e-01, -2.37768039e-01,\n",
       "         -3.96352679e-01,  4.23685402e-01,  4.62122470e-01,\n",
       "         -1.22775137e-01, -8.35632443e-01,  7.96364844e-02,\n",
       "          2.23498136e-01,  3.44207913e-01, -1.72525987e-01,\n",
       "         -3.01010907e-01, -6.53897583e-01,  1.12458188e-02,\n",
       "         -2.72838742e-01,  5.43784678e-01,  2.57591844e-01,\n",
       "         -8.50305617e-01, -3.48775983e-01, -1.58029199e-01,\n",
       "          4.93465126e-01, -2.20202371e-01,  5.84332466e-01,\n",
       "          1.36623040e-01,  1.92556456e-01, -5.56410491e-01,\n",
       "          5.96673310e-01, -8.25742856e-02, -4.04154599e-01,\n",
       "          2.60584950e-01, -4.88995999e-01, -6.54661506e-02,\n",
       "          3.27150941e-01,  3.61850917e-01, -2.00765982e-01,\n",
       "          3.92764449e-01,  2.93132931e-01, -4.53904718e-01,\n",
       "          4.77251500e-01, -2.79700607e-01,  1.57319650e-01,\n",
       "          2.67867297e-01,  1.07239306e-01,  5.47089875e-01,\n",
       "         -5.34174144e-01, -2.46260151e-01,  8.02435949e-02,\n",
       "         -6.10689521e-01,  4.96128760e-02,  2.18357727e-01,\n",
       "          4.98679906e-01, -5.85271716e-01, -2.24376306e-01,\n",
       "          8.16037357e-01, -1.67141438e-01, -2.23387107e-01,\n",
       "          4.08349335e-01, -7.56724179e-01, -4.07556713e-01,\n",
       "          1.11995824e-01,  5.80486715e-01,  6.07976355e-02,\n",
       "         -7.13501930e-01, -7.29536414e-01,  2.25117102e-01,\n",
       "          2.28025928e-01, -8.03027570e-01, -6.73168600e-01,\n",
       "         -3.23997259e-01, -3.20803344e-01, -6.11632168e-02,\n",
       "         -2.11416066e-01,  8.98265094e-02,  5.49852997e-02,\n",
       "         -2.38700047e-01,  2.46564463e-01,  1.13767900e-01,\n",
       "          1.45997718e-01,  3.17483157e-01,  3.04596007e-01,\n",
       "          7.52591640e-02, -2.33992666e-01, -2.51102626e-01,\n",
       "          6.10316098e-02, -3.88778716e-01, -4.17888686e-02,\n",
       "          6.45712316e-01,  6.65624917e-01,  6.84983969e-01,\n",
       "          1.64269924e-01,  1.16480544e-01, -5.01808345e-01,\n",
       "          6.19395316e-01, -8.04159604e-03,  7.94684172e-01,\n",
       "         -3.71285290e-01, -4.91291672e-01, -3.73967201e-01,\n",
       "         -1.57811701e-01, -2.43138764e-02,  3.49189609e-01,\n",
       "          1.55809343e-01, -5.59226990e-01,  2.42014870e-01,\n",
       "          5.11285067e-02, -1.91252619e-01,  7.92277873e-01,\n",
       "          4.75262135e-01, -5.05223155e-01,  5.45136929e-01,\n",
       "          9.49615985e-02, -1.02805287e-01,  3.46735746e-01,\n",
       "          8.63605086e-03,  7.80727267e-01,  6.11980319e-01,\n",
       "          3.41411620e-01,  4.91954923e-01, -2.43826225e-01,\n",
       "         -1.83884084e-01,  1.90621495e-01,  2.88848817e-01,\n",
       "         -2.11734816e-01, -2.18844071e-01,  7.81043768e-01,\n",
       "          5.34661651e-01,  4.17903781e-01, -5.21033525e-01,\n",
       "          2.72932202e-01, -1.85054168e-01, -1.85418680e-01,\n",
       "          7.37049460e-01,  5.09676516e-01, -3.91351461e-01,\n",
       "         -7.21305251e-01, -4.75277662e-01, -1.22358181e-01,\n",
       "         -3.70079614e-02, -4.25249308e-01,  1.37893230e-01,\n",
       "         -2.52345204e-01,  4.19507086e-01, -2.86508590e-01,\n",
       "         -4.82345164e-01,  6.98685467e-01,  5.06158292e-01,\n",
       "         -3.36408436e-01, -8.47721249e-02,  2.41009936e-01,\n",
       "          3.79304469e-01,  5.28555393e-01, -1.73074901e-01,\n",
       "          1.96920618e-01, -1.14495352e-01, -3.79065961e-01,\n",
       "         -5.94766915e-01,  2.08896026e-01,  9.59284604e-02,\n",
       "         -5.78114986e-01, -7.87297785e-01,  4.80065018e-01,\n",
       "         -7.15487242e-01,  4.03461993e-01, -2.02965781e-01,\n",
       "         -7.57851243e-01, -8.13716173e-01,  3.47870082e-01,\n",
       "          7.44869471e-01, -3.95409077e-01, -4.10069734e-01,\n",
       "         -1.96423441e-01, -4.99217957e-01, -1.89589620e-01,\n",
       "          4.15070146e-01, -3.03361177e-01,  3.30401748e-01,\n",
       "          4.09974456e-01, -4.97683167e-01, -5.90535104e-01,\n",
       "         -1.76517308e-01,  2.41326123e-01, -2.55328983e-01,\n",
       "         -3.82531524e-01, -1.39200225e-01, -3.07691932e-01,\n",
       "          1.96683466e-01,  4.26555872e-01,  4.96758111e-02,\n",
       "          3.62868339e-01, -6.87473416e-01,  2.71010756e-01,\n",
       "          3.53670359e-01, -4.98268694e-01,  9.34674963e-02,\n",
       "         -1.82851419e-01,  5.93453109e-01, -1.22432839e-02,\n",
       "          8.33878636e-01,  2.62595087e-01, -4.21775460e-01,\n",
       "          5.79520881e-01,  7.98464417e-02,  1.95723370e-01,\n",
       "         -4.08664525e-01,  3.00931577e-02, -1.10044107e-01,\n",
       "          4.74577814e-01,  8.50696564e-02, -1.61208391e-01,\n",
       "         -4.73316818e-01, -6.42065331e-02, -4.21830505e-01,\n",
       "          4.43620235e-01, -9.13901150e-01,  2.58801784e-02,\n",
       "         -1.27466589e-01,  5.65975845e-01,  1.13466688e-01,\n",
       "          1.60888866e-01,  2.20806748e-01,  4.31174822e-02,\n",
       "          3.61685842e-01,  5.48629344e-01,  1.86212495e-01,\n",
       "         -1.69969097e-01,  1.74074754e-01, -1.47095636e-01,\n",
       "         -5.50078452e-01, -4.86437410e-01, -2.01604720e-02,\n",
       "          1.79449171e-01,  4.03109968e-01, -5.47717035e-01,\n",
       "          3.36043328e-01,  2.20207825e-01,  1.79889537e-02,\n",
       "          1.00903936e-01,  5.35144269e-01,  1.87815800e-01,\n",
       "         -5.44899046e-01,  5.99130914e-02,  3.83350611e-01,\n",
       "         -3.78140688e-01, -6.66068867e-02,  1.00449421e-01,\n",
       "          1.94906324e-01, -5.20616114e-01, -1.96725875e-01,\n",
       "         -3.85578811e-01,  3.58995527e-01, -4.47033763e-01,\n",
       "         -6.84916899e-02,  1.03255779e-01, -5.73403299e-01,\n",
       "         -3.02034140e-01,  3.74240875e-01,  3.65388513e-01,\n",
       "         -4.27674711e-01,  7.26438284e-01,  8.07433948e-02,\n",
       "          4.53657299e-01, -2.61454247e-02,  2.77520478e-01,\n",
       "         -7.09285975e-01, -2.26543754e-01,  4.72153962e-01,\n",
       "          2.19188884e-01, -5.05249560e-01, -6.22152686e-01,\n",
       "          8.67776126e-02,  3.50037515e-01, -2.73484528e-01,\n",
       "          4.65376377e-02,  1.42144322e-01, -2.79201716e-01,\n",
       "         -5.66080749e-01, -6.15423843e-02, -1.44054532e-01,\n",
       "          5.83011746e-01,  5.05876005e-01,  3.17369640e-01,\n",
       "          3.02246690e-01,  6.83853447e-01, -3.69904339e-01,\n",
       "         -6.82646155e-01, -3.68678689e-01, -2.55240679e-01,\n",
       "          7.45234430e-01, -4.02703509e-02,  6.15243196e-01,\n",
       "         -1.95558533e-01, -4.22848314e-02, -2.27295011e-02,\n",
       "          1.10011734e-01,  4.73506004e-01, -5.52492030e-02,\n",
       "          6.11171365e-01, -7.02575564e-01, -3.34874660e-01,\n",
       "          1.38156176e-01,  1.31563053e-01, -3.20051253e-01,\n",
       "         -4.42625791e-01,  6.17559373e-01,  3.18558782e-01,\n",
       "         -5.04152924e-02, -5.29503465e-01,  3.53487194e-01,\n",
       "          3.97198707e-01,  1.05864123e-01,  1.11935154e-01,\n",
       "          6.59773231e-01,  5.59182048e-01,  1.91634685e-01,\n",
       "         -3.64763588e-01,  5.72055340e-01,  5.33252776e-01,\n",
       "         -3.02918494e-01, -1.70597270e-01, -5.43165088e-01,\n",
       "         -6.19890057e-02,  1.79813892e-01, -2.50048727e-01,\n",
       "         -7.46387318e-02, -5.68221450e-01,  9.42723677e-02,\n",
       "          6.40334189e-02, -4.50767986e-02,  7.93617010e-01,\n",
       "         -3.39155316e-01, -6.18197918e-01,  8.11934099e-02,\n",
       "          2.54993469e-01,  1.11125179e-01,  1.83443829e-01,\n",
       "         -4.38552737e-01, -8.27783644e-02, -1.97303638e-01,\n",
       "         -1.92068234e-01, -4.90506947e-01, -7.17464805e-01,\n",
       "          5.46862483e-01,  5.29515892e-02,  2.07469329e-01,\n",
       "         -1.71827465e-01,  6.66891485e-02, -5.73078454e-01,\n",
       "         -4.10159044e-02, -4.06197041e-01, -2.02316225e-01,\n",
       "          1.92491919e-01,  6.75442517e-01, -5.38195431e-01,\n",
       "          1.60510484e-02,  2.53549486e-01,  4.65630680e-01,\n",
       "          1.51592627e-01,  1.76375225e-01,  1.95293486e-01,\n",
       "          6.36740327e-01,  3.71352732e-01,  6.50864780e-01,\n",
       "          1.86979830e-01, -1.81491256e-01,  5.80024779e-01,\n",
       "         -6.67645156e-01,  5.87316275e-01, -1.03291340e-01,\n",
       "         -4.53425556e-01, -5.55865541e-02, -4.38663214e-01,\n",
       "         -3.24334204e-01,  5.11697114e-01, -5.57953678e-02,\n",
       "          3.33573997e-01, -2.41344273e-01, -2.69094914e-01,\n",
       "          3.36890489e-01,  7.16792285e-01, -4.59752917e-01,\n",
       "         -4.55180764e-01, -1.98082864e-01, -8.45106598e-03,\n",
       "         -2.23069400e-01, -4.90298539e-01, -2.63001978e-01,\n",
       "         -3.43627542e-01, -3.64313930e-01, -3.40368271e-01,\n",
       "          3.18703234e-01,  4.65558559e-01,  5.28434753e-01,\n",
       "         -3.74756545e-01, -5.71368098e-01, -7.75264949e-02,\n",
       "         -2.96354860e-01, -3.14744592e-01, -4.56618547e-01,\n",
       "         -4.96895671e-01,  5.86175919e-01, -3.66560608e-01,\n",
       "         -3.90578985e-01,  3.23056489e-01,  6.12380266e-01,\n",
       "         -1.36113092e-02,  4.29621518e-01,  5.25922537e-01,\n",
       "          2.94644564e-01, -3.24861407e-01,  1.52708441e-01,\n",
       "         -7.39957243e-02,  4.93606120e-01,  4.38415796e-01,\n",
       "         -2.48372912e-01, -2.55954117e-01, -4.44171488e-01,\n",
       "          1.36829719e-01, -1.97075978e-02,  1.05340712e-01,\n",
       "         -3.93251359e-01,  5.73947549e-01, -4.84329648e-02,\n",
       "          3.75816882e-01, -6.68080270e-01,  4.98991795e-02,\n",
       "         -3.86964172e-01, -2.61081249e-01, -9.01102349e-02,\n",
       "         -3.92133296e-01, -6.46780372e-01, -6.91595435e-01,\n",
       "         -6.34341836e-01,  7.92691708e-02,  4.68025684e-01,\n",
       "         -4.66655195e-01, -1.22747608e-01,  2.70558923e-01,\n",
       "          2.88611531e-01, -4.02937323e-01,  4.01170045e-01,\n",
       "          4.20894742e-01,  4.13342379e-03,  3.72516185e-01,\n",
       "          4.62973654e-01, -5.78257382e-01,  2.45361090e-01,\n",
       "         -4.17691380e-01,  5.03792882e-01,  7.19836652e-01,\n",
       "         -1.51578486e-02, -6.27986550e-01, -5.33733144e-02,\n",
       "          8.06969047e-01,  2.76295185e-01,  4.59681638e-02,\n",
       "         -4.71472653e-04, -3.15613329e-01, -5.68230808e-01,\n",
       "          2.30221137e-01,  4.22528805e-03,  3.99664938e-01,\n",
       "          9.36895683e-02, -3.93763900e-01, -3.83040816e-01,\n",
       "         -2.54163057e-01,  1.13936421e-02,  3.60977557e-03,\n",
       "         -1.19648827e-02, -5.27560413e-01, -2.95496494e-01,\n",
       "         -1.42603442e-02, -5.66899955e-01, -2.75447339e-01,\n",
       "          3.49829972e-01, -1.38826087e-01,  1.03594819e-02,\n",
       "          5.25721788e-01, -3.73023123e-01,  2.74086833e-01,\n",
       "          8.95531893e-01,  5.05495211e-03, -2.87907720e-01,\n",
       "         -5.90631962e-01, -2.60259118e-02, -2.26613924e-01,\n",
       "         -3.00922871e-01, -5.95325768e-01, -7.17838332e-02,\n",
       "         -4.49277908e-01,  2.42695794e-01,  1.97698101e-01,\n",
       "         -2.35433113e-02,  4.15289849e-01, -3.19852382e-01,\n",
       "          2.14620680e-01, -5.88447452e-01, -6.59071743e-01,\n",
       "          4.42901701e-02,  6.28296435e-01, -5.63813031e-01,\n",
       "         -2.23688260e-01, -7.55471826e-01,  2.32183009e-01,\n",
       "         -4.64487858e-02,  7.69266963e-01,  2.16627553e-01,\n",
       "         -8.54784623e-02,  1.27603292e-01, -6.83447182e-01,\n",
       "         -6.85031235e-01,  1.66744471e-01, -4.93541837e-01,\n",
       "         -3.94635022e-01,  1.56285524e-01,  1.52938068e-01,\n",
       "         -2.09700137e-01, -4.47788537e-01,  9.62854177e-02,\n",
       "          3.34193081e-01,  4.77525264e-01, -1.25665963e-01,\n",
       "          2.10312773e-02,  2.18825564e-01, -3.11087947e-02,\n",
       "         -4.91989642e-01, -2.59054989e-01,  1.11933224e-01,\n",
       "          1.09695829e-01,  3.98773164e-01, -1.24649420e-01,\n",
       "         -2.56363839e-01,  6.99498355e-01,  8.18216503e-01,\n",
       "          2.99298972e-01, -3.06439877e-01, -3.96750212e-01,\n",
       "          3.07312101e-01,  9.86932144e-02, -1.78049490e-01,\n",
       "          2.58211374e-01, -3.65011513e-01,  8.71943235e-02,\n",
       "         -1.80927679e-01, -6.94484591e-01,  4.09430921e-01,\n",
       "          7.34822035e-01,  5.83944678e-01,  7.07487226e-01,\n",
       "         -2.37739906e-01, -7.63778687e-01,  2.86940247e-01,\n",
       "          6.26855135e-01,  7.68628597e-01,  3.53800774e-01,\n",
       "         -8.08433533e-01, -1.42900050e-01,  1.97267935e-01,\n",
       "         -1.29565716e-01,  6.53355956e-01,  2.18515143e-01,\n",
       "          3.33666712e-01, -9.48885903e-02,  1.60333514e-01,\n",
       "         -3.05384934e-01, -5.30210018e-01, -4.74059522e-01,\n",
       "         -2.68544436e-01, -1.58484966e-01,  3.10079247e-01,\n",
       "          6.75876856e-01,  4.01877850e-01, -1.44436955e-01,\n",
       "          6.72935247e-01,  3.57132196e-01, -6.21397078e-01,\n",
       "          4.33325201e-01,  7.33281374e-01,  2.38687828e-01,\n",
       "         -8.23004484e-01, -5.16316235e-01, -1.98425695e-01,\n",
       "         -2.91164994e-01,  1.34630784e-01,  7.97147751e-01,\n",
       "         -8.96699727e-02,  3.94598514e-01,  6.23225272e-02,\n",
       "         -3.32916170e-01,  4.85887229e-02,  5.96847713e-01,\n",
       "         -3.04842025e-01, -1.94966167e-01,  1.07297301e-01,\n",
       "         -8.71980608e-01, -4.16898549e-01,  6.13305829e-02,\n",
       "          3.49448055e-01, -1.59053534e-01, -5.64094365e-01,\n",
       "         -4.15696949e-01, -2.43516371e-01,  3.30827028e-01,\n",
       "          1.12853618e-02, -5.14643133e-01,  2.89718747e-01,\n",
       "          1.48720011e-01, -5.33118665e-01, -9.70687121e-02,\n",
       "         -2.56131530e-01,  3.56514990e-01,  7.13610470e-01,\n",
       "          1.28167942e-01, -3.40324827e-02, -9.03454274e-02,\n",
       "         -5.56584418e-01,  2.53727764e-01, -6.30475461e-01,\n",
       "         -4.57387030e-01,  2.98872918e-01, -1.85306147e-02,\n",
       "         -2.64924136e-03, -4.61187929e-01,  6.14719212e-01,\n",
       "          1.09803500e-02,  5.84665537e-01,  6.03478074e-01,\n",
       "          6.47636503e-02,  5.60164787e-02, -4.42766666e-01,\n",
       "         -7.29300439e-01,  3.14026594e-01,  6.02244914e-01,\n",
       "         -7.13100016e-01, -6.53256059e-01,  1.31108463e-01,\n",
       "          3.56816262e-01,  5.48330784e-01,  5.72247684e-01,\n",
       "          8.24183375e-02,  1.38277367e-01,  2.51370162e-01,\n",
       "          5.90813100e-01,  4.79961455e-01,  3.89255345e-01]], dtype=float32)>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_put = my_bert_model(my_bert_model.dummy_inputs(512), mode=\"eval\", output_features=False)\n",
    "print(type(out_put))\n",
    "print(len(out_put))\n",
    "\n",
    "for item in out_put:\n",
    "    print(type(item))\n",
    "    print(item.shape)\n",
    "\n",
    "out_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape [1, 512]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(512, 21128), dtype=float32, numpy=\n",
       " array([[ 0.2335467 , -0.6062009 ,  0.37243122, ..., -0.02789687,\n",
       "          1.1900101 , -0.04584426],\n",
       "        [ 0.2335467 , -0.6062009 ,  0.37243122, ..., -0.02789687,\n",
       "          1.1900101 , -0.04584426],\n",
       "        [ 0.2335467 , -0.6062009 ,  0.37243122, ..., -0.02789687,\n",
       "          1.1900101 , -0.04584426],\n",
       "        ...,\n",
       "        [ 0.2335467 , -0.6062009 ,  0.37243122, ..., -0.02789687,\n",
       "          1.1900101 , -0.04584426],\n",
       "        [ 0.2335467 , -0.6062009 ,  0.37243122, ..., -0.02789687,\n",
       "          1.1900101 , -0.04584426],\n",
       "        [ 0.2335467 , -0.6062009 ,  0.37243122, ..., -0.02789687,\n",
       "          1.1900101 , -0.04584426]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.05420166, -0.00963133]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       " array([[-5.32185376e-01, -5.94466746e-01, -4.74589109e-01,\n",
       "          5.17674029e-01,  1.22628480e-01, -7.56749511e-01,\n",
       "          1.34524375e-01,  1.23688705e-01, -1.57702968e-01,\n",
       "         -2.52843291e-01, -1.45035118e-01,  2.04627156e-01,\n",
       "         -5.64095825e-02, -4.25636590e-01,  2.76848346e-01,\n",
       "         -6.08348191e-01,  4.81738925e-01,  2.26052582e-01,\n",
       "         -3.99895698e-01,  1.38683245e-01, -2.96139836e-01,\n",
       "          3.53169829e-01,  6.44723654e-01, -1.16646536e-01,\n",
       "          4.53490913e-01,  3.46994728e-01,  6.75476670e-01,\n",
       "          3.64399970e-01,  6.17513657e-01,  5.80862701e-01,\n",
       "         -3.61912698e-01,  4.96865243e-01,  1.65229470e-01,\n",
       "         -3.25312197e-01, -6.50652528e-01, -7.61195302e-01,\n",
       "          1.82747856e-01,  5.71183920e-01,  2.69027203e-01,\n",
       "         -1.17213517e-01,  5.13252020e-01,  5.40110990e-02,\n",
       "         -5.69313288e-01,  3.61962914e-01, -4.03101027e-01,\n",
       "          3.24115217e-01, -3.56740206e-01, -3.81557554e-01,\n",
       "         -7.30749890e-02, -4.02979076e-01, -3.92278910e-01,\n",
       "         -1.61389142e-01, -6.42179310e-01,  6.02091432e-01,\n",
       "         -4.21072870e-01,  5.89100003e-01,  7.17537999e-01,\n",
       "         -1.55539289e-01,  1.87366717e-02,  1.21927828e-01,\n",
       "          5.21108918e-02, -8.40494335e-02,  2.44288415e-01,\n",
       "          2.52806038e-01,  4.16411757e-01,  3.58474880e-01,\n",
       "         -4.28821743e-01, -9.89063606e-02,  4.58797395e-01,\n",
       "         -8.15123022e-02, -3.27809434e-03,  1.76052079e-01,\n",
       "          2.43659303e-01, -1.89572677e-01, -6.62335336e-01,\n",
       "         -1.97402745e-01,  9.65132341e-02, -4.40510780e-01,\n",
       "          7.31261849e-01, -8.99749920e-02, -8.44666898e-01,\n",
       "         -1.14743575e-01,  3.44014376e-01, -8.45113322e-02,\n",
       "          5.04068173e-02,  1.39572680e-01, -2.23658055e-01,\n",
       "          5.94281733e-01,  6.89895868e-01,  3.34038511e-02,\n",
       "         -5.66730499e-01, -1.56636864e-01, -5.13775468e-01,\n",
       "          2.47985706e-01, -4.11930270e-02,  5.72969317e-01,\n",
       "         -3.70020866e-01,  3.47060949e-01,  6.63607121e-01,\n",
       "         -5.99606410e-02, -3.11029971e-01, -5.11855543e-01,\n",
       "         -4.39756870e-01, -2.80487657e-01, -1.01190910e-01,\n",
       "         -1.00086220e-01,  6.81771860e-02, -1.13031581e-01,\n",
       "          6.56773299e-02,  7.14828134e-01,  9.48793907e-03,\n",
       "         -2.10004970e-01, -1.54780462e-01, -6.14800930e-01,\n",
       "          2.06986412e-01,  2.06065550e-01,  1.55964077e-01,\n",
       "          5.93722999e-01, -8.38289917e-01,  1.64727923e-02,\n",
       "          4.69871797e-03,  3.13975185e-01,  4.29619476e-02,\n",
       "         -2.61001408e-01, -5.40361345e-01, -2.02971995e-01,\n",
       "         -1.35111868e-01,  1.19244851e-01, -2.89170772e-01,\n",
       "         -5.83792448e-01,  7.47701764e-01, -3.68047506e-01,\n",
       "          4.38559502e-01,  2.13891640e-01,  2.58925229e-01,\n",
       "          4.12829310e-01, -2.89636463e-01,  2.00699642e-01,\n",
       "         -1.09007180e-01,  1.81851640e-01, -2.08591044e-01,\n",
       "          4.22102213e-01, -5.71742654e-01, -6.26132190e-01,\n",
       "          4.22535449e-01, -4.96051967e-01, -6.80217966e-02,\n",
       "         -6.02424145e-01,  7.48777911e-02,  7.07091212e-01,\n",
       "         -7.75313675e-01,  4.83920723e-01, -3.72896373e-01,\n",
       "         -1.28056258e-01, -3.22980881e-01,  7.87229002e-01,\n",
       "         -1.35867119e-01, -3.09978902e-01, -4.81788337e-01,\n",
       "         -2.47338176e-01,  2.96050370e-01, -1.58408865e-01,\n",
       "         -3.62447977e-01, -1.23471163e-01,  4.47590556e-03,\n",
       "         -2.45749295e-01,  4.28913683e-01, -5.08220732e-01,\n",
       "          3.73818934e-01, -1.48025021e-01, -4.72929806e-01,\n",
       "          2.64812976e-01, -1.14631243e-01,  5.00632942e-01,\n",
       "          1.52671158e-01, -3.98601443e-01,  1.89419061e-01,\n",
       "          4.65894133e-01,  3.31443578e-01, -7.74306893e-01,\n",
       "         -1.47973940e-01,  3.37307863e-02,  5.65947831e-01,\n",
       "         -1.73756689e-01,  5.48717916e-01, -2.90913761e-01,\n",
       "         -1.08418681e-01, -5.10077477e-01,  5.63147254e-02,\n",
       "         -3.55265468e-01, -5.65156400e-01, -6.08104944e-01,\n",
       "          1.98716328e-01, -7.82747507e-01,  2.91409045e-01,\n",
       "         -3.05585891e-01,  3.66767757e-02, -2.32154489e-01,\n",
       "         -2.06111342e-01,  1.85941290e-02,  4.28948998e-01,\n",
       "          4.85250771e-01,  1.25875399e-01,  6.06203601e-02,\n",
       "          1.51051700e-01,  3.78609896e-01,  1.83052093e-01,\n",
       "         -2.16391772e-01,  1.20062083e-01,  7.12381229e-02,\n",
       "          5.94580472e-01, -2.67427832e-01,  3.08778465e-01,\n",
       "          3.99000287e-01,  1.23747863e-01,  2.04988331e-01,\n",
       "         -4.12656277e-01, -3.68005157e-01, -7.07304478e-02,\n",
       "         -2.97793839e-02, -2.68602520e-01,  1.88651204e-01,\n",
       "         -1.24215432e-01,  7.17658401e-01,  3.72414142e-02,\n",
       "          4.89061207e-01,  4.52518731e-01,  3.56701553e-01,\n",
       "         -3.91168177e-01,  2.58318841e-01,  1.57558396e-01,\n",
       "         -3.75100911e-01,  6.62826002e-02, -8.28854144e-01,\n",
       "         -6.03543460e-01,  6.16998851e-01,  7.83173859e-01,\n",
       "         -7.12206602e-01, -2.43483722e-01, -4.32476133e-01,\n",
       "          2.52052546e-01, -2.29542926e-01,  8.79548863e-02,\n",
       "          6.71001732e-01, -5.67681193e-01,  5.00009954e-01,\n",
       "          6.02201045e-01,  5.15822947e-01, -2.77653694e-01,\n",
       "         -4.50492322e-01, -8.57348964e-02, -5.08495808e-01,\n",
       "         -4.05679196e-01, -3.84816527e-02,  6.02359623e-02,\n",
       "         -1.68892443e-02,  2.40623936e-01,  1.62755311e-01,\n",
       "          1.98887870e-01, -3.82085919e-01,  6.20912611e-01,\n",
       "          8.28805447e-01, -6.43430889e-01, -1.07977659e-01,\n",
       "          3.64267260e-01, -9.64037888e-03, -4.80185717e-01,\n",
       "         -3.55126321e-01, -6.72346592e-01, -2.08099619e-01,\n",
       "         -2.17421189e-01,  3.52673560e-01,  6.77658737e-01,\n",
       "         -3.13165754e-01,  3.59627426e-01,  2.65442401e-01,\n",
       "         -8.00844908e-01, -2.04228863e-01, -4.29644078e-01,\n",
       "         -3.64542991e-01, -2.37960786e-01,  3.39795291e-01,\n",
       "         -2.12300196e-01,  7.40574062e-01,  1.25886187e-01,\n",
       "         -2.07799584e-01,  5.64197540e-01,  6.30025506e-01,\n",
       "         -6.00659624e-02, -7.85378754e-01, -2.45560959e-01,\n",
       "         -4.45625663e-01, -3.24316382e-01, -5.51128805e-01,\n",
       "          1.24727398e-01,  1.29476234e-01,  4.54458237e-01,\n",
       "          6.62036359e-01,  3.58877778e-01, -7.54524410e-01,\n",
       "         -5.29268980e-01, -3.27675819e-01, -1.65785402e-01,\n",
       "          5.89758754e-01,  3.83345515e-01, -7.42251351e-02,\n",
       "         -3.70046109e-01, -1.02270924e-01, -1.33844525e-01,\n",
       "         -6.45517632e-02, -5.92571557e-01, -2.35103220e-01,\n",
       "         -3.57312202e-01, -2.12614521e-01,  1.05356276e-01,\n",
       "          4.47338194e-01, -3.95280868e-02,  8.26031923e-01,\n",
       "          5.56772053e-01, -2.27212161e-01, -1.45401582e-01,\n",
       "         -3.67443502e-01,  1.30669057e-01, -2.52766043e-01,\n",
       "         -1.41536653e-01, -3.80829066e-01,  2.59066284e-01,\n",
       "         -1.06474966e-01, -5.82779408e-01, -6.26565456e-01,\n",
       "         -2.20719233e-01,  2.65452594e-01, -4.35460299e-01,\n",
       "          5.18156230e-01,  2.61182219e-01,  1.98313192e-01,\n",
       "          7.08891809e-01,  3.21147501e-01,  1.56774640e-01,\n",
       "          3.96817863e-01,  7.71012843e-01, -3.86487663e-01,\n",
       "          5.78607082e-01,  3.04700434e-01,  7.00536251e-01,\n",
       "          3.41224253e-01,  1.06853075e-01,  4.97982621e-01,\n",
       "          3.72067504e-02,  4.29365188e-02, -5.17827645e-02,\n",
       "          6.33243501e-01, -3.21645021e-01,  1.74280375e-01,\n",
       "          2.03465298e-01, -4.98921782e-01, -1.94544643e-01,\n",
       "         -3.19622993e-01, -3.32783848e-01,  8.50430652e-02,\n",
       "         -2.17876494e-01, -8.39971900e-01, -2.02181190e-01,\n",
       "          4.11776423e-01,  6.03199098e-03,  2.79958487e-01,\n",
       "         -5.50189555e-01, -5.52519523e-02, -5.30937254e-01,\n",
       "          8.36471319e-01, -1.17075510e-01,  2.35798255e-01,\n",
       "          2.37445369e-01,  3.71780582e-02, -1.43815205e-01,\n",
       "          1.11491263e-01,  4.33773339e-01,  4.46228869e-02,\n",
       "         -2.81435758e-01, -5.06820977e-01, -3.14977378e-01,\n",
       "          2.12938756e-01,  4.17885602e-01, -4.31274444e-01,\n",
       "         -6.90622866e-01,  4.24703985e-01, -3.46276909e-01,\n",
       "          5.89702547e-01, -2.54961431e-01,  1.07101046e-01,\n",
       "         -3.44333529e-01,  2.40339600e-02, -1.78252477e-02,\n",
       "         -7.44847953e-01,  6.40698493e-01, -2.35953495e-01,\n",
       "          2.70445704e-01, -6.54471755e-01, -1.38302550e-01,\n",
       "         -4.99604046e-01, -5.21624386e-01, -5.97436488e-01,\n",
       "          5.09756953e-02, -5.00807166e-01,  7.57894337e-01,\n",
       "         -4.12576981e-02,  9.49315652e-02, -3.04563101e-02,\n",
       "         -6.13207877e-01,  1.70505553e-01, -3.85678768e-01,\n",
       "         -2.60800004e-01, -6.10504210e-01,  2.99700260e-01,\n",
       "         -4.49783176e-01, -2.47973070e-01, -1.25933168e-02,\n",
       "          2.70484447e-01,  3.46513718e-01,  1.47956923e-01,\n",
       "         -5.61651051e-01,  2.49960050e-01, -3.21144193e-01,\n",
       "         -7.28896022e-01, -3.73942643e-01, -2.13040113e-01,\n",
       "          5.41613102e-01, -8.96452740e-02, -2.14459047e-01,\n",
       "         -3.08922380e-01, -7.27036834e-01, -3.68306458e-01,\n",
       "          2.34761104e-01,  5.83003640e-01, -1.77448079e-01,\n",
       "          2.73314893e-01, -2.59176552e-01, -5.62771857e-02,\n",
       "         -1.58637822e-01, -9.91502032e-02,  1.23179428e-01,\n",
       "          4.84110296e-01,  4.73206222e-01,  1.55520275e-01,\n",
       "         -2.23135963e-01,  8.64785671e-01,  6.36675596e-01,\n",
       "         -6.84184551e-01,  2.59051770e-01,  2.97523797e-01,\n",
       "          6.29491746e-01,  2.43048206e-01, -7.07362294e-01,\n",
       "         -1.58449411e-01, -7.70412609e-02, -4.09356713e-01,\n",
       "         -5.44787765e-01,  4.74580795e-01,  6.72416925e-01,\n",
       "          1.40231371e-01,  4.25310522e-01,  3.07704091e-01,\n",
       "         -5.31988084e-01, -3.93825889e-01, -4.49371785e-02,\n",
       "          5.29403865e-01,  1.28373010e-02, -3.14134620e-02,\n",
       "          1.90135360e-01, -2.76360840e-01,  6.63052201e-01,\n",
       "          1.15531266e-01,  3.27586651e-01,  1.63105577e-01,\n",
       "         -2.76347905e-01,  5.55724442e-01,  4.31883752e-01,\n",
       "          3.99934441e-01,  1.30225331e-01, -4.58516806e-01,\n",
       "          2.84071982e-01,  4.33917820e-01, -6.73323423e-02,\n",
       "          2.45919839e-01, -3.05410504e-01,  4.23318714e-01,\n",
       "          1.55203670e-01, -2.61415362e-01, -6.02001667e-01,\n",
       "         -8.01859349e-02,  1.07343845e-01,  1.60046130e-01,\n",
       "          3.27779680e-01,  7.91340649e-01,  4.00650620e-01,\n",
       "         -1.96334586e-01, -3.91593099e-01,  1.81743622e-01,\n",
       "         -6.40620887e-02, -2.21072957e-01, -3.05758953e-01,\n",
       "          8.92363310e-01, -7.08797872e-01, -5.50991416e-01,\n",
       "         -3.24643046e-01,  5.08421361e-01, -7.45806769e-02,\n",
       "         -7.23528028e-01,  6.49713755e-01,  1.41098976e-01,\n",
       "          2.78054923e-03, -1.95030645e-02,  3.14465582e-01,\n",
       "         -2.79752582e-01,  1.19500615e-01, -2.31057554e-01,\n",
       "         -4.66548771e-01,  3.00063610e-01,  2.46230930e-01,\n",
       "          1.85533762e-01,  5.25528193e-01,  4.95064437e-01,\n",
       "          6.59768283e-01, -4.36067104e-01,  3.33771765e-01,\n",
       "         -7.21656978e-01, -1.47294074e-01, -1.26726672e-01,\n",
       "          1.20795928e-02, -7.79124975e-01, -2.81315267e-01,\n",
       "         -9.98875126e-02,  2.97336817e-01,  6.34164333e-01,\n",
       "         -3.45312238e-01, -6.65513396e-01, -3.86606753e-02,\n",
       "         -7.38264620e-02,  1.42243117e-01, -2.31682032e-01,\n",
       "          3.73254001e-01,  5.78689873e-02,  7.71330655e-01,\n",
       "         -6.45435393e-01,  1.64658025e-01, -5.19542813e-01,\n",
       "          5.78483522e-01, -4.38373327e-01, -7.77621567e-01,\n",
       "         -1.47353904e-02, -1.23284712e-01,  6.11212373e-01,\n",
       "         -5.34684002e-01, -5.55167377e-01,  5.85899837e-02,\n",
       "         -7.86682546e-01,  2.29697302e-01, -6.22512639e-01,\n",
       "         -6.95917666e-01, -5.85294545e-01,  3.87486666e-01,\n",
       "         -3.03552747e-01,  6.50190562e-02, -5.94570875e-01,\n",
       "         -3.70693095e-02, -2.00676739e-01,  6.01339042e-01,\n",
       "         -3.89993191e-01,  3.49996209e-01,  4.07245070e-01,\n",
       "         -6.63800895e-01, -1.78248346e-01, -3.35249454e-01,\n",
       "         -2.10375682e-01,  3.54240775e-01, -1.05863567e-02,\n",
       "          2.45452523e-01,  1.92596808e-01,  4.47101861e-01,\n",
       "          1.22318923e-01,  1.87948570e-01, -3.83630022e-02,\n",
       "          2.84172148e-01, -3.40960085e-01, -2.15356573e-01,\n",
       "         -4.42398548e-01, -4.09715742e-01, -5.41887939e-01,\n",
       "          6.11366510e-01, -4.51099098e-01, -2.82744884e-01,\n",
       "         -3.83796424e-01, -6.91018939e-01,  2.94331342e-01,\n",
       "          7.10434020e-01,  2.16475591e-01,  3.60182039e-02,\n",
       "          7.10699737e-01,  7.67104805e-01,  3.37605059e-01,\n",
       "         -6.55073941e-01,  2.22157851e-01,  4.16656345e-01,\n",
       "          5.71682155e-01, -3.55777055e-01, -6.55679584e-01,\n",
       "          2.90248513e-01, -5.68151772e-01,  2.24824056e-01,\n",
       "         -1.94673494e-01,  7.21252918e-01,  4.16375130e-01,\n",
       "          1.94444433e-01,  2.55236149e-01, -3.73746037e-01,\n",
       "          6.87517107e-01, -4.92437929e-01, -5.46530902e-01,\n",
       "          3.54473799e-01,  2.09384859e-01, -1.89048663e-01,\n",
       "          1.24007337e-01,  5.73909342e-01,  3.92385155e-01,\n",
       "         -2.27975920e-01,  5.82684934e-01, -1.27749190e-01,\n",
       "          3.87287170e-01, -5.74268997e-01,  8.86739492e-02,\n",
       "         -2.83709258e-01, -1.54832527e-01,  2.54353881e-01,\n",
       "          3.06262285e-01, -6.76902235e-02, -3.91433865e-01,\n",
       "          3.57844234e-02, -5.24047256e-01, -3.48725691e-02,\n",
       "          4.66374680e-02, -1.59111619e-01,  3.39040577e-01,\n",
       "          4.13185745e-01,  5.50620019e-01,  5.84322989e-01,\n",
       "          5.68758726e-01, -5.54458082e-01, -1.59242973e-01,\n",
       "          3.55364531e-01,  6.51147842e-01,  3.52782160e-01,\n",
       "          3.48874152e-01, -5.17095208e-01,  3.97747755e-01,\n",
       "         -1.34786978e-01, -7.20667839e-01, -4.92402107e-01,\n",
       "         -2.84061641e-01, -1.20375551e-01,  1.62339002e-01,\n",
       "          1.12611651e-02,  4.34167922e-01, -6.27730414e-02,\n",
       "          2.61147708e-01,  1.24419153e-01, -1.94678798e-01,\n",
       "         -5.22457242e-01, -4.47298288e-01,  9.98115614e-02,\n",
       "          1.35779843e-01, -1.65523976e-01, -2.85241067e-01,\n",
       "         -5.47193468e-01, -1.97009727e-01,  3.59704375e-01,\n",
       "          5.40480167e-02, -4.58548695e-01,  7.74615765e-01,\n",
       "          2.43415579e-01,  4.22874063e-01, -6.63555562e-01,\n",
       "         -3.62949967e-01,  2.17753313e-02,  7.43065059e-01,\n",
       "          5.50661325e-01, -1.88758045e-01, -3.66079301e-01,\n",
       "         -3.34820479e-01,  5.06300747e-01,  4.80887562e-01,\n",
       "          1.66118190e-01,  1.01398919e-02, -3.22902679e-01,\n",
       "         -1.37098998e-01, -1.80774659e-01,  4.70153898e-01,\n",
       "          5.52276492e-01, -5.29530287e-01,  2.33817957e-02,\n",
       "          3.47382069e-01,  2.56234527e-01,  4.58767921e-01,\n",
       "         -2.01028306e-02,  2.82441247e-02, -2.49947697e-01,\n",
       "          2.29652654e-02,  2.86255747e-01, -4.97998565e-01,\n",
       "          2.96147108e-01, -9.18085933e-01, -1.94736391e-01,\n",
       "         -3.87191415e-01, -5.98182064e-03,  2.25009397e-01,\n",
       "         -4.26181167e-01,  1.40892610e-01,  2.21773341e-01,\n",
       "          4.79172796e-01,  3.94824564e-01,  7.26762593e-01,\n",
       "         -2.58704752e-01,  4.71676141e-01,  8.92129168e-02,\n",
       "          2.27314949e-01,  7.36268461e-02,  3.69454533e-01,\n",
       "          7.52344429e-01, -2.81053573e-01,  1.07757755e-01,\n",
       "          5.66167235e-01, -2.52587616e-01, -4.79122967e-01,\n",
       "         -2.59636138e-02,  1.44860700e-01, -1.44864514e-01,\n",
       "          1.32383838e-01,  3.18168312e-01,  7.45992875e-04,\n",
       "          5.59290349e-01,  6.83981955e-01,  8.15842390e-01,\n",
       "          4.09464002e-01, -2.76302785e-01, -3.74233544e-01,\n",
       "          6.12589598e-01, -5.92374206e-01, -5.69254041e-01,\n",
       "         -3.07280958e-01,  5.41417062e-01,  5.50056696e-01,\n",
       "          1.42418724e-02, -2.94936717e-01, -4.70578551e-01,\n",
       "         -2.44934440e-01,  1.49305582e-01,  2.50992239e-01,\n",
       "         -6.73276186e-01, -2.08291575e-01,  4.58346665e-01,\n",
       "         -2.87626833e-01,  4.04180259e-01,  2.12303475e-01,\n",
       "         -6.68567121e-01,  2.83811241e-01,  6.55703783e-01,\n",
       "          6.85511351e-01, -4.93882224e-03, -4.25714195e-01]], dtype=float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model(bert_model.dummy_inputs(512), mode=\"eval\", output_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "archive_file = \"D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:从文件中还原预训练模型\n",
      "INFO:tensorflow:tvars: [<tf.Variable 'bert_pre_trained_model/bert/embeddings/word_embeddings:0' shape=(21128, 768) dtype=float32, numpy=\n",
      "array([[-0.00986778, -0.03012765,  0.0104761 , ..., -0.03034461,\n",
      "        -0.02464302,  0.03073202],\n",
      "       [ 0.00797483, -0.02573283, -0.00657339, ...,  0.00385186,\n",
      "        -0.01467727, -0.00928151],\n",
      "       [-0.009119  , -0.0116833 , -0.02754286, ..., -0.02966523,\n",
      "        -0.00798262, -0.03110151],\n",
      "       ...,\n",
      "       [ 0.00085306, -0.00071852,  0.03585234, ...,  0.00338991,\n",
      "         0.00717245, -0.00760912],\n",
      "       [-0.00406476, -0.00418313, -0.02780975, ..., -0.012734  ,\n",
      "        -0.01159898, -0.01964439],\n",
      "       [-0.00443669,  0.00640044,  0.0063586 , ...,  0.01330292,\n",
      "        -0.02011607,  0.02084378]], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32, numpy=\n",
      "array([[ 1.8744480e-02,  1.4665171e-02,  1.8223317e-02, ...,\n",
      "         3.1692376e-05, -1.4780769e-02, -3.8693026e-02],\n",
      "       [-2.0115810e-02, -1.9350795e-02,  2.0073261e-02, ...,\n",
      "         8.7640731e-04, -9.4844522e-03,  2.3550007e-02],\n",
      "       [ 1.6765960e-02,  1.2032575e-02, -1.5999869e-02, ...,\n",
      "         3.2890003e-02,  1.7716296e-03, -1.4400680e-03],\n",
      "       ...,\n",
      "       [ 1.3744493e-02,  1.7311700e-02, -9.9539673e-03, ...,\n",
      "         3.2403469e-02,  1.6306985e-02,  3.2090291e-02],\n",
      "       [-2.6222708e-02,  2.4435500e-02, -1.5602108e-02, ...,\n",
      "        -9.6190134e-03,  6.6371886e-03,  1.8695965e-02],\n",
      "       [ 6.3878517e-03,  3.8756814e-02, -1.0162921e-02, ...,\n",
      "        -5.5354931e-03,  2.0346316e-03, -6.9387597e-03]], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32, numpy=\n",
      "array([[ 0.00458759, -0.00898748, -0.00842331, ..., -0.0087436 ,\n",
      "         0.00847065,  0.00290431],\n",
      "       [ 0.01651675, -0.02412579,  0.00274773, ..., -0.03881535,\n",
      "         0.0378297 , -0.03099551]], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32, numpy=\n",
      "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1.], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32, numpy=\n",
      "array([[ 0.00834628, -0.01092904,  0.01791733, ...,  0.00338308,\n",
      "         0.02967088,  0.01833562],\n",
      "       [ 0.0107707 , -0.03975378, -0.03343684, ..., -0.0115241 ,\n",
      "         0.02629375, -0.0105876 ],\n",
      "       [ 0.00689877,  0.00985021, -0.02059093, ..., -0.01377326,\n",
      "        -0.00172573, -0.01621964],\n",
      "       ...,\n",
      "       [ 0.00313889,  0.01151912,  0.00261805, ..., -0.00544315,\n",
      "         0.02220926,  0.01949102],\n",
      "       [-0.00933962, -0.00241254, -0.018046  , ...,  0.015013  ,\n",
      "        -0.02960163, -0.01059819],\n",
      "       [-0.00870874,  0.00094636,  0.01297304, ..., -0.0112409 ,\n",
      "         0.02388389,  0.03507277]], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/bert/pooler/dense/bias:0' shape=(768,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/cls/predictions/output_bias:0' shape=(21128,) dtype=float32, numpy=array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32, numpy=\n",
      "array([[-0.00591543, -0.01227819,  0.00316292, ..., -0.01218215,\n",
      "         0.00667229, -0.00374274],\n",
      "       [-0.01260749, -0.00564763,  0.0213536 , ...,  0.01756957,\n",
      "        -0.00075482, -0.005559  ],\n",
      "       [-0.01144873, -0.0071317 ,  0.02867081, ...,  0.00736138,\n",
      "         0.00940057,  0.01079606],\n",
      "       ...,\n",
      "       [ 0.01514646,  0.00616903,  0.01768546, ...,  0.01686997,\n",
      "        -0.01334446,  0.00578556],\n",
      "       [ 0.02073718, -0.00769128,  0.00998133, ...,  0.03054993,\n",
      "         0.02344996, -0.00884695],\n",
      "       [-0.02110463, -0.01828588,  0.00787046, ...,  0.03061265,\n",
      "        -0.01348061, -0.01570886]], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32, numpy=\n",
      "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0.], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/cls/seq_relationship/output_weights:0' shape=(2, 768) dtype=float32, numpy=\n",
      "array([[ 0.00370986,  0.01586554, -0.02388884, ..., -0.00782186,\n",
      "         0.00686119, -0.01787872],\n",
      "       [ 0.01695313, -0.00729072,  0.03060804, ...,  0.02596333,\n",
      "        -0.01443345,  0.01139142]], dtype=float32)>, <tf.Variable 'bert_pre_trained_model/cls/seq_relationship/output_bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>]\n",
      "Variable: bert/encoder/layer_0/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: cls/predictions/transform/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: cls/predictions/transform/LayerNorm/gamma in ckpt not in trainable variable\n",
      "INFO:tensorflow:Load weights from D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "bert_model._init_from_pretrained_model(archive_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape [1, 512]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(512, 21128), dtype=float32, numpy=\n",
       " array([[2.2154024, 2.57977  , 2.4387329, ..., 0.747318 , 3.8504128,\n",
       "         2.393185 ],\n",
       "        [2.2154024, 2.57977  , 2.4387329, ..., 0.747318 , 3.8504128,\n",
       "         2.393185 ],\n",
       "        [2.2154024, 2.57977  , 2.4387329, ..., 0.747318 , 3.8504128,\n",
       "         2.393185 ],\n",
       "        ...,\n",
       "        [2.2154024, 2.57977  , 2.4387329, ..., 0.747318 , 3.8504128,\n",
       "         2.393185 ],\n",
       "        [2.2154024, 2.57977  , 2.4387329, ..., 0.747318 , 3.8504128,\n",
       "         2.393185 ],\n",
       "        [2.2154024, 2.57977  , 2.4387329, ..., 0.747318 , 3.8504128,\n",
       "         2.393185 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.2736026 ,  0.99370974]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       " array([[-0.72479117, -0.6492197 , -0.6313156 ,  0.7920847 ,  0.33676788,\n",
       "          0.33827484,  0.02391161,  0.9911232 ,  0.77682114,  0.42134544,\n",
       "          0.7303043 , -0.94188184,  0.3583821 ,  0.22749901,  0.62287325,\n",
       "         -0.48044223, -0.9470537 , -0.47611192, -0.53593886,  0.39923307,\n",
       "         -0.24103211,  0.11173998,  0.10579263,  0.8304368 ,  0.8250399 ,\n",
       "         -0.4736875 , -0.03989478,  0.8815407 , -0.4081159 , -0.6050134 ,\n",
       "          0.11440965,  0.6833013 ,  0.6302157 , -0.05027623, -0.10632911,\n",
       "         -0.66221493,  0.47085968,  0.8477666 , -0.04050879, -0.4664754 ,\n",
       "          0.28517765, -0.25663552,  0.97075665,  0.6282056 ,  0.9504943 ,\n",
       "         -0.52040935, -0.02063425, -0.41019747, -0.7112722 , -0.21100737,\n",
       "          0.6963969 , -0.23490939, -0.9614304 ,  0.9847994 , -0.8870247 ,\n",
       "          0.44933897, -0.7774806 , -0.3925969 ,  0.14149573,  0.7613934 ,\n",
       "          0.0736808 , -0.98468006, -0.25667474,  0.00974078,  0.9603422 ,\n",
       "         -0.7161744 , -0.31120753, -0.9019791 , -0.7021571 ,  0.26667807,\n",
       "          0.8814336 ,  0.42620328, -0.37147945,  0.95002955,  0.48181608,\n",
       "         -0.93659025,  0.479027  ,  0.3651491 , -0.58332855,  0.55043674,\n",
       "          0.68763715, -0.31915462, -0.54921025,  0.43392247, -0.29288295,\n",
       "         -0.4779974 ,  0.8210445 ,  0.25552943,  0.6715111 , -0.8595162 ,\n",
       "          0.27816835,  0.49546027, -0.6346139 ,  0.25685462, -0.09118129,\n",
       "          0.45648292,  0.3688654 , -0.9312695 , -0.66953635,  0.6247875 ,\n",
       "          0.8057991 , -0.08364539,  0.97341216,  0.7012485 , -0.95127237,\n",
       "         -0.6702309 , -0.27504227,  0.7320825 ,  0.30220738, -0.7624006 ,\n",
       "          0.36246398, -0.31852433,  0.9332104 , -0.9687189 ,  0.02893895,\n",
       "          0.09183039, -0.93331426, -0.12542176, -0.7917993 ,  0.6179896 ,\n",
       "          0.7638676 ,  0.48631814,  0.04340469, -0.96760714,  0.39164627,\n",
       "          0.30757803, -0.64294815,  0.5844567 , -0.92087406,  0.4938639 ,\n",
       "          0.78410167,  0.67947495, -0.3461571 ,  0.62275916, -0.9337925 ,\n",
       "          0.72711   , -0.09721068, -0.08197643, -0.18997078, -0.31929734,\n",
       "          0.36688545, -0.6236    ,  0.7327418 , -0.4296072 ,  0.565407  ,\n",
       "         -0.4699811 , -0.40657604, -0.32762513, -0.9973949 , -0.8277805 ,\n",
       "         -0.90513   ,  0.08108044, -0.17083909,  0.660946  , -0.57217   ,\n",
       "          0.8920686 , -0.6897082 ,  0.9784788 , -0.29419348, -0.40037742,\n",
       "          0.39322704,  0.789769  ,  0.685629  , -0.2956895 , -0.41915318,\n",
       "          0.5442158 ,  0.6441816 ,  0.05991952, -0.8511714 ,  0.2992839 ,\n",
       "         -0.39053896,  0.41365257, -0.9635104 , -0.38897964, -0.8509558 ,\n",
       "          0.5040027 , -0.7993913 , -0.5957772 , -0.5683009 , -0.40875933,\n",
       "         -0.8580603 ,  0.4837268 ,  0.20662513, -0.02198757, -0.5151559 ,\n",
       "         -0.64928675,  0.9493568 , -0.8912874 , -0.95804524,  0.05086046,\n",
       "         -0.92201203, -0.03722793,  0.4463175 ,  0.6125756 ,  0.6472452 ,\n",
       "          0.11861627, -0.952144  ,  0.865146  ,  0.25657883, -0.5269313 ,\n",
       "         -0.2421062 , -0.73916626,  0.40050042,  0.98359305,  0.01635216,\n",
       "         -0.33812064, -0.9819101 , -0.9286387 ,  0.77079195,  0.4832816 ,\n",
       "         -0.43515465,  0.7822671 ,  0.02600287, -0.44904444, -0.4203244 ,\n",
       "          0.06315883,  0.07589126, -0.85707074, -0.44892615, -0.2929934 ,\n",
       "          0.45041493, -0.6498246 ,  0.9565695 ,  0.24317198, -0.47030678,\n",
       "         -0.9663311 ,  0.82092416,  0.10377744, -0.3823303 ,  0.84524333,\n",
       "          0.6944442 , -0.8973847 ,  0.5357234 ,  0.21012715, -0.09417748,\n",
       "          0.83587843, -0.93030447,  0.5482501 , -0.69400173, -0.4334539 ,\n",
       "         -0.5223914 ,  0.13979544,  0.41348568, -0.49908316,  0.00468988,\n",
       "         -0.79776037,  0.09973577, -0.5654123 , -0.47273386, -0.06318863,\n",
       "         -0.57170427,  0.65818983,  0.5941787 , -0.27762675,  0.53791213,\n",
       "          0.32407412,  0.02483807,  0.46587247,  0.8999826 ,  0.10817569,\n",
       "         -0.42399356, -0.21442227,  0.12784205, -0.51865935, -0.6475225 ,\n",
       "          0.38454413,  0.90473336, -0.93661433, -0.68916136, -0.47088042,\n",
       "          0.5183096 ,  0.4022706 ,  0.04589849, -0.41254434, -0.28179044,\n",
       "         -0.20525976, -0.28269255,  0.34439975,  0.2047308 ,  0.17181458,\n",
       "          0.37790558, -0.30498764,  0.30530456, -0.07404022,  0.7230437 ,\n",
       "         -0.95908684,  0.7717529 ,  0.12134778, -0.27417183, -0.44744813,\n",
       "         -0.21554731, -0.15264557, -0.6554478 , -0.87294906, -0.63161993,\n",
       "          0.8559319 ,  0.9131252 , -0.90151477,  0.20163025, -0.99921554,\n",
       "          0.74334866,  0.87605256,  0.5790145 ,  0.9275167 ,  0.45460004,\n",
       "         -0.26906112,  0.69387275, -0.0767839 ,  0.63874793, -0.87367076,\n",
       "          0.36689174, -0.5032154 ,  0.6206039 ,  0.63774854,  0.21639517,\n",
       "          0.3440435 ,  0.38080138, -0.86645937, -0.4767645 ,  0.87806106,\n",
       "         -0.9667496 , -0.7769191 ,  0.8760508 , -0.39451927, -0.81564707,\n",
       "          0.3318998 , -0.1619317 , -0.70591545, -0.69763976,  0.38742733,\n",
       "          0.20248123, -0.26518238, -0.27964932, -0.6960635 ,  0.20018436,\n",
       "         -0.5642825 ,  0.95710343,  0.42500055, -0.19993289, -0.56104743,\n",
       "         -0.43460616, -0.53606695, -0.7341087 ,  0.33706978,  0.3287089 ,\n",
       "          0.18546805,  0.85656005, -0.9642875 ,  0.9139505 ,  0.543142  ,\n",
       "         -0.58334124,  0.11840134,  0.55667305, -0.86696   , -0.9435564 ,\n",
       "          0.16314223, -0.5922869 ,  0.99410594,  0.12237133,  0.19471976,\n",
       "          0.05772713,  0.5260066 ,  0.9434889 ,  0.4778875 , -0.6881343 ,\n",
       "          0.22113878,  0.0048845 , -0.36037388, -0.4171575 ,  0.21330346,\n",
       "         -0.21012767,  0.26540878,  0.9573616 , -0.2406115 , -0.75617325,\n",
       "         -0.27989164, -0.11258808, -0.18868122, -0.8982136 ,  0.77404857,\n",
       "          0.8215447 , -0.2319849 , -0.2702044 ,  0.21940844,  0.34644127,\n",
       "          0.99712586, -0.01761855, -0.296423  , -0.77335036,  0.19442831,\n",
       "         -0.73495436,  0.9599821 , -0.27973977,  0.22296393,  0.33802542,\n",
       "         -0.21125661, -0.86382073, -0.36273012, -0.34462282, -0.33530897,\n",
       "         -0.546762  ,  0.9811446 ,  0.59900784, -0.20075342, -0.57620335,\n",
       "          0.56108993,  0.24357286,  0.93282425,  0.90750456,  0.17482421,\n",
       "          0.17804502, -0.7436455 ,  0.17171668, -0.5808124 , -0.19082431,\n",
       "          0.36366853,  0.03710475,  0.9543116 , -0.77897495,  0.47272632,\n",
       "          0.7020182 ,  0.992871  ,  0.36655   , -0.46258053, -0.10522631,\n",
       "          0.81735635, -0.45821223, -0.29191667, -0.6116171 , -0.30469733,\n",
       "         -0.32748923,  0.7468459 , -0.16613977, -0.2874948 ,  0.11303621,\n",
       "         -0.1771843 ,  0.93704015, -0.05509295, -0.85654235,  0.4780902 ,\n",
       "         -0.4209414 , -0.44920436,  0.02999729,  0.00676016,  0.9087558 ,\n",
       "          0.7486414 ,  0.73023355,  0.07203043,  0.10982632, -0.89866257,\n",
       "          0.7849115 , -0.9018776 , -0.34077168,  0.03283001, -0.41292587,\n",
       "          0.47683218,  0.40165126,  0.8997325 ,  0.16989931, -0.9881479 ,\n",
       "          0.4422143 ,  0.66319734,  0.5549686 , -0.5651893 ,  0.4971171 ,\n",
       "         -0.88154685,  0.36105874,  0.93507046,  0.94715613, -0.5897768 ,\n",
       "         -0.4463282 ,  0.10099199,  0.26238093,  0.76471144,  0.64591044,\n",
       "         -0.50021195,  0.02465718,  0.98894346, -0.34000584,  0.40457737,\n",
       "         -0.3117253 , -0.40521735,  0.8472579 ,  0.67064637,  0.08339438,\n",
       "         -0.9527085 ,  0.9193319 , -0.5108688 , -0.8337311 , -0.8852946 ,\n",
       "         -0.42394274, -0.7792299 ,  0.9751232 ,  0.9036205 , -0.29706526,\n",
       "         -0.8394159 ,  0.5635489 ,  0.966375  , -0.98792857,  0.26908773,\n",
       "         -0.23761836,  0.83462816,  0.61188596,  0.21250533, -0.73906577,\n",
       "          0.32741958,  0.87085813, -0.49377513, -0.964511  ,  0.11638468,\n",
       "         -0.02308727, -0.79677963,  0.39924967, -0.45167157,  0.1728601 ,\n",
       "          0.44961098, -0.8353031 , -0.9396218 , -0.8878129 , -0.03470821,\n",
       "         -0.05981782, -0.53543717,  0.40152025, -0.10033555, -0.7327441 ,\n",
       "         -0.5960648 ,  0.67861074,  0.43860883, -0.6975964 ,  0.62885296,\n",
       "         -0.45791155, -0.8320219 , -0.32897222,  0.9862105 ,  0.48798585,\n",
       "         -0.8712192 , -0.759752  ,  0.51513284,  0.45508608, -0.63034606,\n",
       "          0.2061054 , -0.5843455 , -0.7289297 , -0.6731356 ,  0.6150502 ,\n",
       "         -0.7602682 ,  0.04649751, -0.10664906,  0.4391441 , -0.67171836,\n",
       "         -0.88859284,  0.09326132,  0.6089011 ,  0.37985462, -0.49609545,\n",
       "         -0.5561574 ,  0.7223995 ,  0.09871301,  0.14921823, -0.3572859 ,\n",
       "          0.93272704,  0.21846637,  0.963533  ,  0.5914015 , -0.615481  ,\n",
       "          0.41066653,  0.43584892, -0.967552  , -0.3053403 ,  0.25966883,\n",
       "          0.30591688,  0.40743938,  0.53243244,  0.36683983, -0.56844085,\n",
       "         -0.9131345 ,  0.41252252,  0.8698825 , -0.87904334,  0.9621112 ,\n",
       "         -0.70902747,  0.04292341,  0.7152049 ,  0.40639004,  0.7345355 ,\n",
       "         -0.8725694 ,  0.8403541 ,  0.78396696, -0.0606447 , -0.56303644,\n",
       "         -0.9743391 , -0.6594928 , -0.11109444,  0.6217336 ,  0.7882321 ,\n",
       "         -0.8337048 , -0.6699985 ,  0.7454165 ,  0.76836836,  0.8309367 ,\n",
       "         -0.5655453 , -0.9194267 ,  0.29564133,  0.29428312,  0.6294241 ,\n",
       "          0.00392163, -0.91742915,  0.42257616,  0.12879464,  0.1407092 ,\n",
       "          0.6686205 , -0.82649803,  0.1517715 ,  0.29456702, -0.44639474,\n",
       "         -0.7344061 ,  0.5198811 , -0.9273877 , -0.64123   ,  0.23551849,\n",
       "         -0.09216409, -0.15202901, -0.70361394,  0.43394497, -0.7151805 ,\n",
       "          0.2632656 ,  0.8568079 , -0.03608191,  0.6885522 ,  0.75319886,\n",
       "          0.8272765 ,  0.9931802 , -0.7848403 , -0.5821968 , -0.41932875,\n",
       "         -0.8961121 ,  0.6378757 , -0.2896972 ,  0.5441427 ,  0.14227833,\n",
       "          0.54260516, -0.3824659 ,  0.95051074, -0.9569491 ,  0.8869129 ,\n",
       "         -0.5732441 ,  0.5528477 ,  0.26632375, -0.63660353,  0.26025537,\n",
       "         -0.9073729 , -0.683912  ,  0.8512668 , -0.951504  ,  0.12387152,\n",
       "          0.06346609, -0.85863215, -0.24908459,  0.86244464,  0.27514493,\n",
       "          0.35065666, -0.5157429 ,  0.2081127 , -0.2673515 ,  0.12616426,\n",
       "          0.7029147 ,  0.03966253, -0.58303756,  0.4877427 ,  0.75507504,\n",
       "          0.16978548, -0.06537072,  0.4520285 ,  0.02338163, -0.05269878,\n",
       "         -0.40101594, -0.07443154,  0.16050752,  0.7494444 , -0.59542143,\n",
       "         -0.53270435,  0.11271886,  0.5904759 ,  0.81042993,  0.82307434,\n",
       "         -0.69565064, -0.77895206,  0.64650935,  0.24772437,  0.16938621,\n",
       "         -0.30161482,  0.8020451 , -0.28613335,  0.1681575 ,  0.7118449 ,\n",
       "          0.6979729 , -0.30711627, -0.69199824,  0.8003054 ,  0.25799307,\n",
       "         -0.35608286, -0.1334966 ,  0.42426953, -0.00977225, -0.2784167 ,\n",
       "          0.32785946,  0.41673216,  0.6857134 ,  0.93464035,  0.02774049,\n",
       "         -0.30258608, -0.27776283,  0.9958558 , -0.9089354 , -0.24715862,\n",
       "          0.1417341 ,  0.20425144, -0.9401245 ,  0.4791727 , -0.95549953,\n",
       "          0.16209355,  0.67095953,  0.5187057 ,  0.19067186, -0.66023326,\n",
       "         -0.5839916 ,  0.21139808,  0.09930738, -0.16342042,  0.2578999 ,\n",
       "         -0.21396707,  0.8922893 , -0.8411762 , -0.8435828 ,  0.907115  ,\n",
       "         -0.18549293, -0.9614084 ,  0.2550414 , -0.07618499, -0.9684438 ,\n",
       "          0.60122365, -0.75511456, -0.47446623,  0.93304527, -0.22220059,\n",
       "         -0.160337  , -0.62146044,  0.5727748 , -0.9329133 ,  0.30102572,\n",
       "          0.16838369, -0.05109387,  0.04849344, -0.6298537 ,  0.5907569 ,\n",
       "         -0.71491975,  0.9385535 , -0.95302266, -0.9622366 ,  0.10362082,\n",
       "         -0.89191526,  0.06408888,  0.6235438 , -0.1374807 , -0.7125289 ,\n",
       "         -0.6439741 , -0.65110123,  0.9866672 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model(bert_model.dummy_inputs(512), mode=\"eval\", output_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# from easytransfer.model_zoo import modeling_utils, modeling_bert\n",
    "# importlib.reload(modeling_utils)\n",
    "# importlib.reload(modeling_bert)\n",
    "# from easytransfer.model_zoo.modeling_bert import BertConfig, BertPreTrainedModel, MyBertPreTrainedModel\n",
    "# from easytransfer.model_zoo.modeling_utils import PretrainedConfig\n",
    "\n",
    "# bert_config = BertConfig.get(bert_config_path)\n",
    "# my_bert_model = MyBertPreTrainedModel(bert_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从文件中还原预训练模型\n",
      "network_name_to_variable ['my_bert_pre_trained_model/bert/embeddings/word_embeddings', 'my_bert_pre_trained_model/bert/embeddings/position_embeddings', 'my_bert_pre_trained_model/bert/embeddings/token_type_embeddings', 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/gamma', 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/beta', 'my_bert_pre_trained_model/bert/pooler/dense/kernel', 'my_bert_pre_trained_model/bert/pooler/dense/bias', 'my_bert_pre_trained_model/cls/predictions/output_bias', 'my_bert_pre_trained_model/cls/predictions/transform/dense/kernel', 'my_bert_pre_trained_model/cls/predictions/transform/dense/bias', 'my_bert_pre_trained_model/cls/seq_relationship/output_weights', 'my_bert_pre_trained_model/cls/seq_relationship/output_bias']\n",
      "Variable: bert/encoder/layer_0/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_0/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_1/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_10/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_11/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_2/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_3/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_4/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_5/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_6/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_7/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/key/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/value/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/attention/self/value/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/LayerNorm/gamma in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_8/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/key/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/query/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/attention/self/query/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/intermediate/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/intermediate/dense/kernel in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/dense/bias in ckpt not in trainable variable\n",
      "Variable: bert/encoder/layer_9/output/dense/kernel in ckpt not in trainable variable\n",
      "Variable: cls/predictions/transform/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: cls/predictions/transform/LayerNorm/gamma in ckpt not in trainable variable\n",
      "INFO:tensorflow:Load weights from D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "my_bert_model._init_from_pretrained_model(archive_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape [1, 512]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(512, 21128), dtype=float32, numpy=\n",
       " array([[ 0.49204844,  0.48211277,  0.4653633 , ..., -3.3483171 ,\n",
       "         -1.4075947 , -1.322042  ],\n",
       "        [ 0.49204844,  0.48211277,  0.4653633 , ..., -3.3483171 ,\n",
       "         -1.4075947 , -1.322042  ],\n",
       "        [ 0.49204844,  0.48211277,  0.4653633 , ..., -3.3483171 ,\n",
       "         -1.4075947 , -1.322042  ],\n",
       "        ...,\n",
       "        [ 0.49204844,  0.48211277,  0.4653633 , ..., -3.3483171 ,\n",
       "         -1.4075947 , -1.322042  ],\n",
       "        [ 0.49204844,  0.48211277,  0.4653633 , ..., -3.3483171 ,\n",
       "         -1.4075947 , -1.322042  ],\n",
       "        [ 0.49204844,  0.48211277,  0.4653633 , ..., -3.3483171 ,\n",
       "         -1.4075947 , -1.322042  ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[-0.10657424,  1.0788873 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
       " array([[-0.644912  , -0.8142637 , -0.7562132 ,  0.8439509 , -0.4156421 ,\n",
       "          0.71163225,  0.5849316 ,  0.99201447,  0.648055  , -0.12371132,\n",
       "          0.72192055, -0.7951201 ,  0.95257246,  0.36918184,  0.04723987,\n",
       "          0.3721022 ,  0.8576133 ,  0.9778229 , -0.82935387,  0.6579165 ,\n",
       "         -0.7851755 ,  0.7243696 , -0.12899421, -0.5347973 ,  0.93856394,\n",
       "         -0.9101124 , -0.09328426,  0.65775484, -0.619769  , -0.4699368 ,\n",
       "         -0.68870956,  0.6141955 ,  0.577313  , -0.6824024 ,  0.7306259 ,\n",
       "         -0.551244  , -0.58933973, -0.7721239 , -0.98710865, -0.29948384,\n",
       "          0.7502068 , -0.98410064,  0.9091328 ,  0.88417965,  0.92806315,\n",
       "         -0.7183224 , -0.5863045 ,  0.6812449 , -0.20710534,  0.03473917,\n",
       "          0.64848524,  0.65355754,  0.34005743, -0.32026225,  0.9944841 ,\n",
       "         -0.35155708,  0.57292706, -0.19826181,  0.56059873, -0.531352  ,\n",
       "          0.8773943 ,  0.81073195, -0.7169879 ,  0.3989627 , -0.3452273 ,\n",
       "          0.5700699 ,  0.29588142,  0.47986424,  0.12512626, -0.33919725,\n",
       "          0.48525757, -0.27200967, -0.4088256 , -0.15953591, -0.7568425 ,\n",
       "         -0.89436334,  0.97611934,  0.32351226, -0.14383171, -0.67957616,\n",
       "          0.6077838 , -0.48131043,  0.12812024,  0.4324635 ,  0.71999913,\n",
       "         -0.5515745 ,  0.20447516, -0.9085596 , -0.67981803, -0.99890125,\n",
       "          0.13318384, -0.08013991, -0.5263611 ,  0.9235609 ,  0.59509283,\n",
       "          0.6982975 , -0.8874529 , -0.2409646 , -0.76673186,  0.21977091,\n",
       "          0.9712031 ,  0.13373162,  0.9038547 ,  0.77625346, -0.95454234,\n",
       "          0.35128367, -0.23782422, -0.70501834, -0.863929  ,  0.57473063,\n",
       "          0.08947176, -0.263586  ,  0.8022954 ,  0.91465735,  0.388279  ,\n",
       "          0.8995521 ,  0.41899297,  0.4159346 , -0.22902086,  0.8449519 ,\n",
       "          0.7902042 ,  0.93163866, -0.90342104, -0.9501837 , -0.18231453,\n",
       "         -0.5864988 , -0.77507544,  0.7282102 , -0.40930647,  0.40896702,\n",
       "          0.06803574, -0.4133953 ,  0.9262825 , -0.7675787 ,  0.05876373,\n",
       "          0.87704974,  0.9221627 ,  0.808348  , -0.02022034, -0.76213986,\n",
       "         -0.6879464 , -0.9107929 ,  0.22232105,  0.9359905 , -0.39067343,\n",
       "          0.34936246, -0.35344103, -0.38191208,  0.2993986 , -0.99066067,\n",
       "          0.14911944, -0.1477473 ,  0.8944491 ,  0.7286187 , -0.3949308 ,\n",
       "          0.69393635, -0.43111932,  0.30509263, -0.8243934 , -0.5489152 ,\n",
       "          0.9261391 ,  0.99160296,  0.7809945 ,  0.81233007, -0.6665769 ,\n",
       "          0.59694076, -0.35808697, -0.04227257, -0.82569176, -0.60226566,\n",
       "         -0.50300413,  0.80180484,  0.48034272,  0.8911294 ,  0.3667928 ,\n",
       "          0.3381181 ,  0.37399212, -0.68735194,  0.08699127, -0.86421126,\n",
       "         -0.11917098, -0.6746359 ,  0.1073937 , -0.76152015, -0.23184575,\n",
       "          0.6540279 ,  0.16422999, -0.777831  , -0.9968395 , -0.7942546 ,\n",
       "         -0.7367132 ,  0.22241437,  0.73017913,  0.93418854, -0.39515054,\n",
       "          0.56938475, -0.21526691,  0.20400596, -0.07266255, -0.22606257,\n",
       "          0.53312033,  0.5595049 ,  0.37906384, -0.8763995 , -0.05147495,\n",
       "         -0.69046634, -0.8701308 ,  0.53369075,  0.3497853 ,  0.09783869,\n",
       "          0.53083867,  0.9767024 ,  0.62186015, -0.6828037 , -0.71727526,\n",
       "         -0.39433753,  0.8466229 , -0.6000123 , -0.9553445 ,  0.81968397,\n",
       "         -0.8779028 , -0.3449324 ,  0.8914083 , -0.9831709 ,  0.9467538 ,\n",
       "         -0.4511059 ,  0.9508155 , -0.24965534, -0.91440314,  0.91895336,\n",
       "          0.13782682, -0.82452375,  0.7351438 , -0.60935867,  0.9165352 ,\n",
       "          0.9921074 ,  0.36689165,  0.725217  ,  0.7883077 ,  0.9607409 ,\n",
       "         -0.4566876 ,  0.26807174,  0.19415645,  0.6356301 ,  0.81566674,\n",
       "         -0.5271388 ,  0.5272719 , -0.69655865, -0.48535132,  0.7017407 ,\n",
       "         -0.03751886,  0.6468551 ,  0.29388094, -0.5068194 , -0.6452713 ,\n",
       "         -0.21889271,  0.33343464, -0.4436436 ,  0.269304  ,  0.9256073 ,\n",
       "         -0.7412327 , -0.64663076,  0.86947083,  0.72189933, -0.72348946,\n",
       "          0.8365275 ,  0.7808445 , -0.6401218 ,  0.71829146, -0.37897074,\n",
       "          0.15913083, -0.5675049 , -0.640882  ,  0.9378969 , -0.6147028 ,\n",
       "          0.7784658 ,  0.44262454, -0.13876818, -0.95041573,  0.54769826,\n",
       "          0.47279537, -0.3000337 , -0.8373117 , -0.16321096, -0.56812334,\n",
       "         -0.04665964, -0.8631836 , -0.264669  ,  0.4950229 , -0.5735987 ,\n",
       "         -0.54461396, -0.83085746, -0.45619255,  0.05081789,  0.03846927,\n",
       "         -0.8458396 ,  0.7662555 ,  0.9517932 , -0.41161823, -0.85379374,\n",
       "          0.7352481 ,  0.8705525 ,  0.1652437 , -0.11390996,  0.8198981 ,\n",
       "          0.87062347, -0.10362533,  0.3367907 ,  0.02304708, -0.99286044,\n",
       "          0.4431998 ,  0.2003814 ,  0.83908004, -0.07534309,  0.35992622,\n",
       "          0.65201557,  0.6748536 , -0.9060224 ,  0.88882536,  0.06171915,\n",
       "          0.15798001,  0.3275757 , -0.12054811,  0.42410374,  0.99275446,\n",
       "          0.66829515, -0.44846642,  0.6411625 ,  0.36964002,  0.6357609 ,\n",
       "         -0.5892194 , -0.08554135, -0.84380144, -0.37596235,  0.92744035,\n",
       "          0.09875829,  0.9767021 ,  0.36139295, -0.12547585, -0.4932037 ,\n",
       "          0.11453473, -0.29674408,  0.74639666,  0.58523357, -0.2329092 ,\n",
       "          0.5425968 ,  0.7094164 , -0.06347653,  0.4736203 ,  0.6357891 ,\n",
       "          0.5904448 ,  0.69073325, -0.8635242 , -0.5200812 , -0.95873773,\n",
       "         -0.608319  ,  0.81051534,  0.9359309 ,  0.36670497, -0.10022413,\n",
       "         -0.6768676 , -0.18503328,  0.7746064 ,  0.33583212, -0.9995444 ,\n",
       "         -0.72799206,  0.39720124, -0.23559178, -0.08403026,  0.44404063,\n",
       "         -0.26242855, -0.14779069,  0.00563524, -0.88431716,  0.33132446,\n",
       "         -0.9493902 , -0.8872548 ,  0.57873225, -0.7971241 ,  0.51419073,\n",
       "         -0.6040647 , -0.45862404,  0.16554667,  0.15097807,  0.8182963 ,\n",
       "          0.6632845 ,  0.6984428 , -0.65248185, -0.6406958 , -0.86650884,\n",
       "         -0.7151301 ,  0.5026843 , -0.15192473,  0.06238618,  0.71081185,\n",
       "         -0.3630162 ,  0.08327163, -0.92651284,  0.05494431,  0.81559217,\n",
       "         -0.5728767 , -0.36642808,  0.6093243 ,  0.05775379, -0.39641368,\n",
       "          0.22658436,  0.50486535, -0.46258742, -0.7094107 , -0.62418205,\n",
       "         -0.63498586, -0.84917176,  0.03060981, -0.74040604, -0.4483742 ,\n",
       "          0.8633134 ,  0.6175806 ,  0.5560078 , -0.8811664 ,  0.9812356 ,\n",
       "          0.34360504, -0.88584757,  0.22069126,  0.5015266 ,  0.3099109 ,\n",
       "         -0.5895254 ,  0.88494545, -0.6616972 , -0.8077651 ,  0.592592  ,\n",
       "          0.01484708,  0.0548723 ,  0.03116905, -0.69420135, -0.5416344 ,\n",
       "         -0.2386778 ,  0.82488835,  0.4476673 ,  0.5384233 , -0.87516993,\n",
       "         -0.7008271 ,  0.15139711, -0.67547166, -0.6953751 , -0.26889503,\n",
       "         -0.9308191 ,  0.17860399, -0.48747894,  0.37916747, -0.9866323 ,\n",
       "         -0.5263173 , -0.602404  , -0.15965943,  0.01958547, -0.6596012 ,\n",
       "         -0.93775207,  0.26763165,  0.63171405,  0.5346589 , -0.9765624 ,\n",
       "          0.2797724 ,  0.48880327, -0.12162959, -0.6997908 , -0.21283832,\n",
       "         -0.771458  , -0.2200179 ,  0.46181384,  0.9822701 ,  0.05773713,\n",
       "          0.8210475 ,  0.49425507, -0.15354042,  0.39360029,  0.17011648,\n",
       "          0.02602462,  0.79737127,  0.4143187 ,  0.5967658 ,  0.56374925,\n",
       "         -0.18142848,  0.93501914, -0.22580178,  0.7934992 , -0.15074256,\n",
       "         -0.75401926,  0.7209293 , -0.8000479 ,  0.5088716 ,  0.50510335,\n",
       "         -0.8405889 , -0.5480542 , -0.6789434 ,  0.74608207, -0.12887144,\n",
       "         -0.25884768,  0.42468527,  0.986521  , -0.09528098, -0.07913455,\n",
       "          0.62448776,  0.98406154,  0.6343048 , -0.42588416, -0.8745159 ,\n",
       "         -0.9614079 ,  0.14072903, -0.87466985, -0.8604871 , -0.28448257,\n",
       "          0.03657597,  0.54869443,  0.97699285, -0.07116704,  0.7338506 ,\n",
       "          0.11940264, -0.7942161 ,  0.20885943, -0.5634007 , -0.20159346,\n",
       "          0.08860627, -0.6349736 , -0.03951307,  0.9130703 , -0.40366092,\n",
       "         -0.8438504 ,  0.11887582,  0.82106227,  0.26118898, -0.88690484,\n",
       "          0.26901117,  0.85524964,  0.8718595 ,  0.82462794,  0.6615471 ,\n",
       "         -0.7549009 ,  0.21583803,  0.2984006 ,  0.742414  , -0.904383  ,\n",
       "          0.7023947 ,  0.8264383 ,  0.71484125, -0.1463775 ,  0.24709961,\n",
       "         -0.8039546 , -0.6615162 ,  0.8096816 ,  0.486841  ,  0.06742561,\n",
       "         -0.77313733,  0.3100363 , -0.21903156,  0.10237017,  0.5026812 ,\n",
       "         -0.82170606,  0.5632344 , -0.75561464,  0.329068  , -0.9476549 ,\n",
       "         -0.22539842,  0.90256315,  0.56013584, -0.33292615,  0.21068373,\n",
       "          0.44642144,  0.57036513, -0.9225166 , -0.23552768,  0.4877917 ,\n",
       "          0.54589325, -0.07415379, -0.66123986,  0.792862  , -0.16838911,\n",
       "         -0.82487667,  0.69335634,  0.00191158, -0.9628108 ,  0.9625069 ,\n",
       "         -0.05689428, -0.00343285,  0.7524005 , -0.08069166, -0.6253614 ,\n",
       "         -0.9848745 ,  0.38889977, -0.51154125,  0.00435403, -0.5195634 ,\n",
       "          0.08545367,  0.03588622, -0.19739017,  0.88555515, -0.6221172 ,\n",
       "          0.7907035 ,  0.8712705 , -0.86934084,  0.9372257 ,  0.14157581,\n",
       "          0.03031703, -0.6634393 , -0.9340521 ,  0.7850573 , -0.00656173,\n",
       "          0.5329991 , -0.04257858,  0.6763902 ,  0.62875134, -0.88404286,\n",
       "          0.5945527 , -0.8703875 ,  0.6091391 , -0.23007157, -0.9629526 ,\n",
       "         -0.16115741,  0.44710964, -0.4550076 , -0.54014134, -0.29475805,\n",
       "          0.66340363, -0.44058105, -0.9142449 , -0.35800025, -0.70875406,\n",
       "          0.00679717,  0.13640152, -0.23506555,  0.6652491 ,  0.21515584,\n",
       "          0.47803575,  0.12050834, -0.64078814,  0.10699237,  0.7893672 ,\n",
       "         -0.4462347 , -0.9985307 , -0.23995204, -0.8556521 , -0.46051636,\n",
       "          0.5730059 ,  0.47837165,  0.5485629 ,  0.30430883,  0.9096127 ,\n",
       "         -0.4611998 ,  0.3462992 ,  0.21871893, -0.9318021 ,  0.58759916,\n",
       "          0.2199605 , -0.493363  ,  0.63597447, -0.77629215, -0.7241929 ,\n",
       "          0.14769311,  0.6240505 , -0.88016456, -0.6328813 , -0.64562994,\n",
       "          0.44747812, -0.03582959,  0.48618796, -0.14277016,  0.8713104 ,\n",
       "         -0.08377484, -0.49761373, -0.07400648, -0.4511378 ,  0.47176993,\n",
       "          0.60171735,  0.8535628 ,  0.04121241,  0.17567773, -0.9592801 ,\n",
       "          0.35564822,  0.25021383, -0.49547058,  0.97712386, -0.8435859 ,\n",
       "          0.7060847 ,  0.69537777,  0.0885365 ,  0.8286545 , -0.03485963,\n",
       "         -0.41762605, -0.6889086 ,  0.27662098, -0.6802791 ,  0.04476646,\n",
       "          0.77163786,  0.91690403, -0.720631  , -0.36212015, -0.42747712,\n",
       "          0.35820454, -0.20934166, -0.8638724 ,  0.86535203,  0.2947213 ,\n",
       "         -0.48946816, -0.21316259,  0.5588858 , -0.502581  ,  0.6298823 ,\n",
       "         -0.36740917, -0.9815128 ,  0.770586  ,  0.6931565 , -0.250756  ,\n",
       "         -0.8578681 , -0.27322808, -0.51525134, -0.7161601 , -0.43506145,\n",
       "          0.40818894, -0.10817758, -0.6273817 ,  0.1625165 ,  0.9895712 ,\n",
       "         -0.5935566 , -0.8302075 ,  0.71865684, -0.48464572,  0.66550326,\n",
       "         -0.41702437,  0.15600723, -0.29565033, -0.40979725,  0.55914044,\n",
       "          0.15805462, -0.11230757, -0.7584712 , -0.80090016,  0.8903522 ,\n",
       "         -0.5966782 , -0.84935796, -0.26926786, -0.18603422, -0.9428244 ,\n",
       "         -0.14619291, -0.602193  , -0.5955132 ,  0.90949774,  0.28143913,\n",
       "          0.70097345, -0.11779772,  0.44728068, -0.7180283 , -0.562547  ,\n",
       "          0.57035357,  0.01811192, -0.31381223, -0.83738774, -0.19354372,\n",
       "         -0.68749577,  0.5430086 ,  0.08137634, -0.93153673,  0.40768716,\n",
       "         -0.24972185, -0.2701579 , -0.49033463, -0.17617173, -0.39491084,\n",
       "         -0.96985245,  0.37887546, -0.5141721 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_bert_model(my_bert_model.dummy_inputs(512), mode=\"eval\", output_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(bert_model.weights, my_bert_model.weights):\n",
    "    print(tf.equal(x, y).numpy().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'bert_pre_trained_model/bert/embeddings/word_embeddings:0' shape=(21128, 768) dtype=float32, numpy=\n",
      "array([[ 0.02615827,  0.01094903, -0.01868878, ...,  0.09030139,\n",
      "         0.0028486 ,  0.00642775],\n",
      "       [ 0.00211436,  0.02164099,  0.00108996, ...,  0.08090564,\n",
      "         0.00178312,  0.02494784],\n",
      "       [ 0.01467745,  0.00050856,  0.00283794, ...,  0.08360939,\n",
      "         0.01208044,  0.02821462],\n",
      "       ...,\n",
      "       [ 0.03456404,  0.00210567,  0.00852101, ...,  0.00853979,\n",
      "         0.03371229,  0.00985317],\n",
      "       [ 0.05406349,  0.02890619,  0.02626012, ...,  0.0525924 ,\n",
      "         0.06508742,  0.03532186],\n",
      "       [ 0.02002425,  0.00229523, -0.00892451, ...,  0.07987329,\n",
      "        -0.05615233,  0.02471835]], dtype=float32)>\n",
      "<tf.Variable 'my_bert_pre_trained_model/bert/embeddings/word_embeddings:0' shape=(21128, 768) dtype=float32, numpy=\n",
      "array([[ 0.02615827,  0.01094903, -0.01868878, ...,  0.09030139,\n",
      "         0.0028486 ,  0.00642775],\n",
      "       [ 0.00211436,  0.02164099,  0.00108996, ...,  0.08090564,\n",
      "         0.00178312,  0.02494784],\n",
      "       [ 0.01467745,  0.00050856,  0.00283794, ...,  0.08360939,\n",
      "         0.01208044,  0.02821462],\n",
      "       ...,\n",
      "       [ 0.03456404,  0.00210567,  0.00852101, ...,  0.00853979,\n",
      "         0.03371229,  0.00985317],\n",
      "       [ 0.05406349,  0.02890619,  0.02626012, ...,  0.0525924 ,\n",
      "         0.06508742,  0.03532186],\n",
      "       [ 0.02002425,  0.00229523, -0.00892451, ...,  0.07987329,\n",
      "        -0.05615233,  0.02471835]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(bert_model.weights[0])\n",
    "print(my_bert_model.weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_pre_trained_model/bert/embeddings/word_embeddings:0',\n",
       " 'bert_pre_trained_model/bert/embeddings/position_embeddings:0',\n",
       " 'bert_pre_trained_model/bert/embeddings/token_type_embeddings:0',\n",
       " 'bert_pre_trained_model/bert/embeddings/LayerNorm/gamma:0',\n",
       " 'bert_pre_trained_model/bert/embeddings/LayerNorm/beta:0',\n",
       " 'bert_pre_trained_model/bert/pooler/dense/kernel:0',\n",
       " 'bert_pre_trained_model/bert/pooler/dense/bias:0',\n",
       " 'bert_pre_trained_model/cls/predictions/output_bias:0',\n",
       " 'bert_pre_trained_model/cls/predictions/transform/dense/kernel:0',\n",
       " 'bert_pre_trained_model/cls/predictions/transform/dense/bias:0',\n",
       " 'bert_pre_trained_model/cls/seq_relationship/output_weights:0',\n",
       " 'bert_pre_trained_model/cls/seq_relationship/output_bias:0']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in bert_model.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_bert_pre_trained_model/bert/embeddings/word_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/position_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/token_type_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/gamma:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/beta:0',\n",
       " 'my_bert_pre_trained_model/bert/pooler/dense/kernel:0',\n",
       " 'my_bert_pre_trained_model/bert/pooler/dense/bias:0',\n",
       " 'my_bert_pre_trained_model/cls/predictions/output_bias:0',\n",
       " 'my_bert_pre_trained_model/cls/predictions/transform/dense/kernel:0',\n",
       " 'my_bert_pre_trained_model/cls/predictions/transform/dense/bias:0',\n",
       " 'my_bert_pre_trained_model/cls/seq_relationship/output_weights:0',\n",
       " 'my_bert_pre_trained_model/cls/seq_relationship/output_bias:0']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in my_bert_model.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_bert_pre_trained_model/bert/embeddings/word_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/position_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/token_type_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/gamma:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/beta:0',\n",
       " 'my_bert_pre_trained_model/bert/pooler/dense/kernel:0',\n",
       " 'my_bert_pre_trained_model/bert/pooler/dense/bias:0']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in my_bert_model.bert.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_bert_pre_trained_model/bert/embeddings/word_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/position_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/token_type_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/gamma:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/beta:0']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in my_bert_model.bert.embeddings.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_bert_pre_trained_model/cls/predictions/output_bias:0',\n",
       " 'my_bert_pre_trained_model/cls/predictions/transform/dense/kernel:0',\n",
       " 'my_bert_pre_trained_model/cls/predictions/transform/dense/bias:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/word_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/position_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/token_type_embeddings:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/gamma:0',\n",
       " 'my_bert_pre_trained_model/bert/embeddings/LayerNorm/beta:0']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in my_bert_model.mlm.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['my_bert_pre_trained_model/cls/seq_relationship/output_weights:0',\n",
       " 'my_bert_pre_trained_model/cls/seq_relationship/output_bias:0']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[v.name for v in my_bert_model.nsp.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('bert/embeddings/LayerNorm/beta', [768]),\n",
       " ('bert/embeddings/LayerNorm/gamma', [768]),\n",
       " ('bert/embeddings/position_embeddings', [512, 768]),\n",
       " ('bert/embeddings/token_type_embeddings', [2, 768]),\n",
       " ('bert/embeddings/word_embeddings', [21128, 768]),\n",
       " ('bert/encoder/layer_0/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_0/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_0/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_0/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_0/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_0/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_0/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_0/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_0/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_0/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_1/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_1/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_1/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_1/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_1/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_1/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_1/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_1/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_1/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_1/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_10/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_10/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_10/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_10/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_10/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_10/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_10/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_10/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_10/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_10/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_11/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_11/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_11/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_11/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_11/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_11/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_11/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_11/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_11/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_11/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_2/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_2/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_2/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_2/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_2/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_2/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_2/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_2/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_2/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_2/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_3/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_3/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_3/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_3/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_3/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_3/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_3/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_3/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_3/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_3/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_4/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_4/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_4/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_4/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_4/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_4/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_4/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_4/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_4/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_4/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_5/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_5/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_5/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_5/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_5/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_5/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_5/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_5/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_5/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_5/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_6/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_6/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_6/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_6/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_6/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_6/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_6/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_6/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_6/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_6/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_7/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_7/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_7/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_7/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_7/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_7/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_7/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_7/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_7/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_7/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_8/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_8/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_8/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_8/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_8/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_8/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_8/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_8/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_8/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_8/output/dense/kernel', [3072, 768]),\n",
       " ('bert/encoder/layer_9/attention/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_9/attention/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_9/attention/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/output/dense/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/attention/self/key/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/self/key/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/attention/self/query/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/self/query/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/attention/self/value/bias', [768]),\n",
       " ('bert/encoder/layer_9/attention/self/value/kernel', [768, 768]),\n",
       " ('bert/encoder/layer_9/intermediate/dense/bias', [3072]),\n",
       " ('bert/encoder/layer_9/intermediate/dense/kernel', [768, 3072]),\n",
       " ('bert/encoder/layer_9/output/LayerNorm/beta', [768]),\n",
       " ('bert/encoder/layer_9/output/LayerNorm/gamma', [768]),\n",
       " ('bert/encoder/layer_9/output/dense/bias', [768]),\n",
       " ('bert/encoder/layer_9/output/dense/kernel', [3072, 768]),\n",
       " ('bert/pooler/dense/bias', [768]),\n",
       " ('bert/pooler/dense/kernel', [768, 768]),\n",
       " ('cls/predictions/output_bias', [21128]),\n",
       " ('cls/predictions/transform/LayerNorm/beta', [768]),\n",
       " ('cls/predictions/transform/LayerNorm/gamma', [768]),\n",
       " ('cls/predictions/transform/dense/bias', [768]),\n",
       " ('cls/predictions/transform/dense/kernel', [768, 768]),\n",
       " ('cls/seq_relationship/output_bias', [2]),\n",
       " ('cls/seq_relationship/output_weights', [2, 768])]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.train.list_variables('D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = tf.train.load_checkpoint(\"D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\")\n",
    "var_to_shape_map = reader.get_variable_to_shape_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert/encoder/layer_0/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/intermediate/dense/kernel',\n",
       " 'bert/embeddings/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/attention/self/key/bias',\n",
       " 'bert/encoder/layer_11/attention/output/dense/kernel',\n",
       " 'bert/embeddings/LayerNorm/gamma',\n",
       " 'bert/embeddings/position_embeddings',\n",
       " 'bert/encoder/layer_5/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/attention/self/query/bias',\n",
       " 'bert/encoder/layer_1/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_5/output/dense/bias',\n",
       " 'bert/embeddings/token_type_embeddings',\n",
       " 'bert/encoder/layer_10/intermediate/dense/kernel',\n",
       " 'bert/embeddings/word_embeddings',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_0/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_0/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_0/attention/self/key/bias',\n",
       " 'bert/encoder/layer_0/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/key/bias',\n",
       " 'bert/encoder/layer_0/attention/self/query/bias',\n",
       " 'bert/encoder/layer_11/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/attention/self/key/bias',\n",
       " 'bert/encoder/layer_0/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_0/attention/self/value/bias',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/output/dense/bias',\n",
       " 'bert/encoder/layer_0/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_0/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_1/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_1/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/key/bias',\n",
       " 'bert/encoder/layer_1/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_1/attention/self/query/bias',\n",
       " 'bert/encoder/layer_1/attention/self/value/bias',\n",
       " 'bert/encoder/layer_1/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_1/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_10/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_1/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_1/output/dense/bias',\n",
       " 'bert/encoder/layer_1/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_10/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_10/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_10/attention/self/key/bias',\n",
       " 'bert/encoder/layer_10/attention/self/query/bias',\n",
       " 'bert/encoder/layer_10/attention/self/value/bias',\n",
       " 'bert/encoder/layer_11/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_10/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_10/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_10/output/dense/bias',\n",
       " 'bert/encoder/layer_10/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_11/attention/self/value/bias',\n",
       " 'bert/encoder/layer_11/attention/self/value/kernel',\n",
       " 'cls/predictions/output_bias',\n",
       " 'bert/encoder/layer_11/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_11/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_11/output/dense/bias',\n",
       " 'bert/encoder/layer_11/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_2/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/key/bias',\n",
       " 'bert/encoder/layer_2/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/query/bias',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_2/attention/self/value/bias',\n",
       " 'bert/encoder/layer_2/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_2/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_7/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_2/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_2/output/dense/bias',\n",
       " 'bert/encoder/layer_2/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_3/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/query/bias',\n",
       " 'bert/encoder/layer_3/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_3/attention/self/value/bias',\n",
       " 'bert/encoder/layer_3/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_3/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_3/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_3/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_3/output/dense/bias',\n",
       " 'bert/encoder/layer_3/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_4/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/key/bias',\n",
       " 'bert/encoder/layer_4/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/value/bias',\n",
       " 'bert/encoder/layer_4/attention/self/query/bias',\n",
       " 'bert/encoder/layer_9/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_4/attention/self/value/bias',\n",
       " 'bert/encoder/layer_4/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_4/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_4/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_4/output/dense/bias',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_4/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_5/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_5/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/key/bias',\n",
       " 'bert/encoder/layer_5/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/query/bias',\n",
       " 'bert/encoder/layer_5/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_5/attention/self/value/bias',\n",
       " 'bert/encoder/layer_5/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_5/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_6/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/key/bias',\n",
       " 'bert/encoder/layer_6/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/query/bias',\n",
       " 'bert/encoder/layer_6/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_6/attention/self/value/bias',\n",
       " 'bert/encoder/layer_6/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_6/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_6/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_6/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_6/output/dense/bias',\n",
       " 'bert/encoder/layer_6/output/dense/kernel',\n",
       " 'bert/encoder/layer_7/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_7/attention/self/key/bias',\n",
       " 'bert/encoder/layer_7/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/query/bias',\n",
       " 'bert/encoder/layer_7/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_7/attention/self/value/bias',\n",
       " 'bert/encoder/layer_7/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_7/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_7/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_7/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_7/output/dense/bias',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/attention/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/key/bias',\n",
       " 'bert/encoder/layer_8/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_8/attention/self/query/bias',\n",
       " 'bert/encoder/layer_8/attention/self/value/bias',\n",
       " 'bert/encoder/layer_8/attention/self/value/kernel',\n",
       " 'bert/encoder/layer_8/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_8/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_8/output/LayerNorm/gamma',\n",
       " 'bert/encoder/layer_8/output/dense/bias',\n",
       " 'bert/encoder/layer_8/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/attention/output/dense/bias',\n",
       " 'bert/encoder/layer_9/attention/output/dense/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/key/kernel',\n",
       " 'bert/encoder/layer_9/attention/self/query/bias',\n",
       " 'bert/encoder/layer_9/attention/self/query/kernel',\n",
       " 'bert/encoder/layer_9/intermediate/dense/bias',\n",
       " 'bert/encoder/layer_9/intermediate/dense/kernel',\n",
       " 'bert/encoder/layer_9/output/LayerNorm/beta',\n",
       " 'bert/encoder/layer_9/output/dense/bias',\n",
       " 'bert/encoder/layer_9/output/dense/kernel',\n",
       " 'bert/pooler/dense/bias',\n",
       " 'bert/pooler/dense/kernel',\n",
       " 'cls/predictions/transform/LayerNorm/beta',\n",
       " 'cls/predictions/transform/LayerNorm/gamma',\n",
       " 'cls/predictions/transform/dense/bias',\n",
       " 'cls/predictions/transform/dense/kernel',\n",
       " 'cls/seq_relationship/output_bias',\n",
       " 'cls/seq_relationship/output_weights']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(var_to_shape_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
