{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./eztransfer_modelzoo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为环境变量做好准备\n",
    "import os\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_text = \"\"\"\n",
    "HOME=./eztransfer_modelzoo\n",
    "\"\"\"\n",
    "\n",
    "load_dotenv(stream=StringIO(env_text), override=True, verbose=True)\n",
    "os.environ.get(\"HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\code\\\\github\\\\EasyTransfer',\n",
       " 'd:\\\\code\\\\github\\\\EasyTransfer\\\\examples',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles\\\\lib\\\\python',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\python37.zip',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\DLLs',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\lib',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp',\n",
       " '',\n",
       " 'C:\\\\Users\\\\tzh\\\\AppData\\\\Roaming\\\\Python\\\\Python37\\\\site-packages',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\tzh\\\\.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 让本地的 easytransfer 的优先级更高\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*********** tf.__version__ is 1.13.2 ******\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'easytransfer' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\tzh\\AppData\\Local\\Temp/ipykernel_24624/3724060076.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0measytransfer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0measytransfer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0measytransfer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'easytransfer' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "# 导入 easytransfer, 并验证, 因为原始的没有 __version__ 这个参数\n",
    "import importlib\n",
    "import easytransfer\n",
    "importlib.reload(easytransfer)\n",
    "easytransfer.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Anaconda3\\\\envs\\\\nlp\\\\lib\\\\site-packages\\\\ipykernel_launcher.py', '--ip=127.0.0.1', '--stdin=9003', '--control=9001', '--hb=9000', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"6dfe9eea-9ff8-47f3-a521-a2f335e0efda\"', '--shell=9002', '--transport=\"tcp\"', '--iopub=9004', '--f=C:\\\\Users\\\\tzh\\\\AppData\\\\Local\\\\Temp\\\\tmp-45620Vs5j8w6FvsXg.json']\n"
     ]
    }
   ],
   "source": [
    "# jupyter 特殊操作\n",
    "old_argv = sys.argv\n",
    "print(old_argv)\n",
    "sys.argv = old_argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*********** tf.__version__ is 1.13.2 ******\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from easytransfer import Config, base_model, layers, model_zoo, preprocessors\n",
    "from easytransfer.datasets import CSVReader, CSVWriter\n",
    "from easytransfer.evaluators import classification_eval_metrics\n",
    "from easytransfer.losses import softmax_cross_entropy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# 设置随机种子\n",
    "tf.set_random_seed(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassification(base_model):\n",
    "    \"\"\"\n",
    "    定义文本分类模型\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TextClassification, self).__init__(**kwargs)\n",
    "        self.user_defined_config = kwargs[\"user_defined_config\"]\n",
    "\n",
    "    def build_logits(self, features, mode=None):\n",
    "        \"\"\"构图\n",
    "\n",
    "        Args:\n",
    "            features ([type]): [description]\n",
    "            mode ([type], optional): [description]. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        # 负责对原始数据进行预处理，生成模型需要的特征，比如：input_ids, input_mask, segment_ids等\n",
    "        preprocessor = preprocessors.get_preprocessor(\n",
    "            self.pretrain_model_name_or_path, user_defined_config=self.user_defined_config\n",
    "        )\n",
    "        # 负责构建网络的backbone\n",
    "        model = model_zoo.get_pretrained_model(self.pretrain_model_name_or_path)\n",
    "\n",
    "        dense = layers.Dense(self.num_labels, kernel_initializer=layers.get_initializer(0.02), name=\"dense\")\n",
    "        input_ids, input_mask, segment_ids, label_ids = preprocessor(features)\n",
    "        _, pooled_output = model([input_ids, input_mask, segment_ids], mode=mode)\n",
    "        logits = dense(pooled_output)\n",
    "\n",
    "        # 用于 continue finetune\n",
    "        # self.check_and_init_from_checkpoint(mode)\n",
    "        return logits, label_ids\n",
    "\n",
    "    def build_loss(self, logits, labels):\n",
    "        \"\"\"定义损失函数\n",
    "\n",
    "        Args:\n",
    "            logits ([type]): logits returned from build_logits\n",
    "            labels ([type]): labels returned from build_logits\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        return softmax_cross_entropy(labels, self.num_labels, logits)\n",
    "\n",
    "    def build_eval_metrics(self, logits, labels):\n",
    "        \"\"\"定义评估指标\n",
    "\n",
    "        Args:\n",
    "            logits ([type]): logits returned from build_logits\n",
    "            labels ([type]): labels returned from build_logits\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        return classification_eval_metrics(logits, labels, self.num_labels)\n",
    "\n",
    "    def build_predictions(self, output):\n",
    "        \"\"\"定义预测输出\n",
    "\n",
    "        Args:\n",
    "            output ([type]): returned from build_logits\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        logits, _ = output\n",
    "        predictions = dict()\n",
    "        index = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        predictions[\"predict_index\"] = index\n",
    "        predictions[\"predict_softmax\"] = tf.nn.softmax(logits)\n",
    "        # 核心是理解 shape, 最后一维才是类别数量, 第一个维度是 batch_size\n",
    "        predictions[\"predict_prob\"] = tf.gather(tf.nn.softmax(logits), index, axis=-1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config_json):\n",
    "    config = Config(mode=\"train_and_evaluate_on_the_fly\", config_json=config_json)\n",
    "    app = TextClassification(user_defined_config=config)\n",
    "\n",
    "    train_reader = CSVReader(\n",
    "        input_glob=app.train_input_fp, is_training=True, input_schema=app.input_schema, batch_size=app.train_batch_size,\n",
    "    )\n",
    "    eval_reader = CSVReader(\n",
    "        input_glob=app.eval_input_fp, is_training=False, input_schema=app.input_schema, batch_size=app.eval_batch_size,\n",
    "    )\n",
    "\n",
    "    app.run_train_and_evaluate(train_reader=train_reader, eval_reader=eval_reader)\n",
    "\n",
    "\n",
    "def predict(config_json):\n",
    "    config = Config(mode=\"predict_on_the_fly\", config_json=config_json)\n",
    "    app = TextClassification(user_defined_config=config)\n",
    "\n",
    "    pred_reader = CSVReader(\n",
    "        input_glob=app.predict_input_fp,\n",
    "        is_training=False,\n",
    "        input_schema=app.input_schema,\n",
    "        batch_size=app.predict_batch_size,\n",
    "    )\n",
    "    pred_writer = CSVWriter(output_glob=app.predict_output_fp, output_schema=app.output_schema)\n",
    "\n",
    "    result = app.run_predict(reader=pred_reader, writer=None, checkpoint_path=app.predict_checkpoint_path)\n",
    "    for row in result:\n",
    "        print(row)\n",
    "        break\n",
    "\n",
    "\n",
    "def evaluate(config_json):\n",
    "    config = Config(mode=\"evaluate_on_the_fly\", config_json=config_json)\n",
    "    app = TextClassification(user_defined_config=config)\n",
    "\n",
    "    eval_reader = CSVReader(\n",
    "        input_glob=app.eval_input_fp, is_training=False, input_schema=app.input_schema, batch_size=app.eval_batch_size,\n",
    "    )\n",
    "\n",
    "    result = app.run_evaluate(reader=eval_reader, checkpoint_path=app.eval_ckpt_path)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***************** modelZooBasePath ./eztransfer_modelzoo\\.eztransfer_modelzoo ***************\n",
      "INFO:tensorflow:total number of training examples 1000\n",
      "INFO:tensorflow:***********Running in train_and_evaluate_on_the_fly mode***********\n",
      "INFO:tensorflow:***********Disable Tao***********\n",
      "INFO:tensorflow:***********NCCL_IB_DISABLE 0***********\n",
      "INFO:tensorflow:***********NCCL_P2P_DISABLE 0***********\n",
      "INFO:tensorflow:***********NCCL_SHM_DISABLE 0***********\n",
      "INFO:tensorflow:***********NCCL_MAX_NRINGS 4***********\n",
      "INFO:tensorflow:***********NCCL_MIN_NRINGS 2***********\n",
      "INFO:tensorflow:***********NCCL_LAUNCH_MODE PARALLEL***********\n",
      "INFO:tensorflow:***********TF_JIT_PROFILING False***********\n",
      "INFO:tensorflow:***********PAI_ENABLE_HLO_DUMPER False***********\n",
      "INFO:tensorflow:***********Single worker, Single gpu, Don't use distribution strategy***********\n",
      "INFO:tensorflow:model_dir: model_dir\n",
      "INFO:tensorflow:num workers: 1\n",
      "INFO:tensorflow:num gpus: 1\n",
      "INFO:tensorflow:learning rate: 1e-05\n",
      "INFO:tensorflow:train batch size: 32\n",
      "INFO:tensorflow:global batch size: 32\n",
      "INFO:tensorflow:num accumulated batches: 1\n",
      "INFO:tensorflow:num model replica: 1\n",
      "INFO:tensorflow:num train examples per epoch: 1000\n",
      "INFO:tensorflow:num epochs: 5.0\n",
      "INFO:tensorflow:train steps: 157\n",
      "INFO:tensorflow:save steps: 31\n",
      "INFO:tensorflow:throttle secs: 100\n",
      "INFO:tensorflow:keep checkpoint max: 1\n",
      "INFO:tensorflow:warmup ratio: 0.1\n",
      "INFO:tensorflow:gradient clip: True\n",
      "INFO:tensorflow:clip norm value: 1.0\n",
      "INFO:tensorflow:log step count steps: 100\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_dir', '_tf_random_seed': 123123, '_save_summary_steps': 100, '_save_checkpoints_steps': 31, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 1024\n",
      "inter_op_parallelism_threads: 1024\n",
      "gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "  allow_growth: true\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001CFF75BF688>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function EzTransEstimator._build_model_fn.<locals>.model_fn at 0x000001CFAB695AF8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:num eval steps: None\n",
      "INFO:tensorflow:num_parallel_batches 1\n",
      "INFO:tensorflow:shuffle_buffer_size None\n",
      "INFO:tensorflow:prefetch_buffer_size 1\n",
      "INFO:tensorflow:batch_size 32\n",
      "INFO:tensorflow:distribution_strategy None\n",
      "INFO:tensorflow:num_micro_batches 1\n",
      "INFO:tensorflow:input_schema label:str:1,content:str:1\n",
      "INFO:tensorflow:D:/code/py_nlp_classify/data/small/train.csv, total number of training examples 1000\n",
      "INFO:tensorflow:num_parallel_batches 1\n",
      "INFO:tensorflow:shuffle_buffer_size None\n",
      "INFO:tensorflow:prefetch_buffer_size 1\n",
      "INFO:tensorflow:batch_size 8\n",
      "INFO:tensorflow:distribution_strategy None\n",
      "INFO:tensorflow:num_micro_batches 1\n",
      "INFO:tensorflow:input_schema label:str:1,content:str:1\n",
      "INFO:tensorflow:D:/code/py_nlp_classify/data/small/dev.csv, total number of eval examples 100\n",
      "INFO:tensorflow:*********Calling tf.estimator.train_and_evaluate *********\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 31 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Random shuffle on the whole 1000 training examples\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "INFO:tensorflow:Load weights from D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\easytransfer\\preprocessors\\preprocessor.py:325: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, use\n",
      "    tf.py_function, which takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    \n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\losses\\losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\training\\learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:*******Warmup 15 steps***********\n",
      "INFO:tensorflow:*******Using adam optimizer************\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:*******Num of trainable variables 102893977************\n",
      "INFO:tensorflow:*******Clip Gradients************\n",
      "INFO:tensorflow:*******Clip Norm Value 1.0*********\n",
      "INFO:tensorflow:*********Num towers is 1 *********\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_dir\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.859805, step = 0\n",
      "INFO:tensorflow:Saving checkpoints for 31 into model_dir\\model.ckpt.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Load weights from D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\n",
      "INFO:tensorflow:empty data to evaluate\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-01-30T09:20:42Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_dir\\model.ckpt-31\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2022-01-30-09:20:47\n",
      "INFO:tensorflow:Saving dict for global step 31: global_step = 31, loss = 2.5703368, py_accuracy = 0.21, py_macro_f1 = 0.10164191, py_micro_f1 = 0.21, py_weighted_f1 = 0.13078609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 31: model_dir\\model.ckpt-31\n",
      "INFO:tensorflow:Saving checkpoints for 62 into model_dir\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (100 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 93 into model_dir\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (100 secs).\n",
      "INFO:tensorflow:global_step/sec: 1.37586\n",
      "INFO:tensorflow:loss = 2.14808, step = 100 (72.684 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 124 into model_dir\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (100 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 155 into model_dir\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (100 secs).\n",
      "INFO:tensorflow:Saving checkpoints for 157 into model_dir\\model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (100 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Load weights from D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\n",
      "INFO:tensorflow:empty data to evaluate\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-01-30T09:22:09Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_dir\\model.ckpt-157\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2022-01-30-09:22:14\n",
      "INFO:tensorflow:Saving dict for global step 157: global_step = 157, loss = 2.1276407, py_accuracy = 0.41, py_macro_f1 = 0.37596843, py_micro_f1 = 0.41, py_weighted_f1 = 0.40845755\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 157: model_dir\\model.ckpt-157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 1.8996964.\n"
     ]
    }
   ],
   "source": [
    "config_json = json.load(open(\"user_config.json\", \"r\", encoding=\"utf-8\"))\n",
    "train(config_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***************** modelZooBasePath ./eztransfer_modelzoo\\.eztransfer_modelzoo ***************\n",
      "INFO:tensorflow:num eval steps: None\n",
      "INFO:tensorflow:***********Running in evaluate_on_the_fly mode***********\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\tzh\\AppData\\Local\\Temp\\tmpcohh14xs\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\tzh\\\\AppData\\\\Local\\\\Temp\\\\tmpcohh14xs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': intra_op_parallelism_threads: 1024\n",
      "inter_op_parallelism_threads: 1024\n",
      "gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "  allow_growth: true\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001CFC72A2D88>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function EzTransEstimator._build_model_fn.<locals>.model_fn at 0x000001CFF76060D8>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:num_parallel_batches 1\n",
      "INFO:tensorflow:shuffle_buffer_size None\n",
      "INFO:tensorflow:prefetch_buffer_size 1\n",
      "INFO:tensorflow:batch_size 8\n",
      "INFO:tensorflow:distribution_strategy None\n",
      "INFO:tensorflow:num_micro_batches 1\n",
      "INFO:tensorflow:input_schema label:str:1,content:str:1\n",
      "INFO:tensorflow:D:/code/py_nlp_classify/data/small/dev.csv, total number of eval examples 100\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Load weights from D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\n",
      "INFO:tensorflow:empty data to evaluate\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2022-01-30T09:28:02Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_dir/model.ckpt-157\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2022-01-30-09:28:06\n",
      "INFO:tensorflow:Saving dict for global step 157: global_step = 157, loss = 2.1276407, py_accuracy = 0.41, py_macro_f1 = 0.37596843, py_micro_f1 = 0.41, py_weighted_f1 = 0.40845755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "C:\\Anaconda3\\envs\\nlp\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 157: model_dir/model.ckpt-157\n",
      "{'loss': 2.1276407, 'py_accuracy': 0.41, 'py_macro_f1': 0.37596843, 'py_micro_f1': 0.41, 'py_weighted_f1': 0.40845755, 'global_step': 157}\n"
     ]
    }
   ],
   "source": [
    "config_json[\"evaluate_config\"][\"eval_checkpoint_path\"] = config_json[\"evaluate_config\"][\"eval_checkpoint_path\"].format(157)\n",
    "evaluate(config_json)\n",
    "# {'loss': 2.1276107, 'py_accuracy': 0.41, 'py_macro_f1': 0.37596843, 'py_micro_f1': 0.41, 'py_weighted_f1': 0.40845755, 'global_step': 157}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dbc7cfacfb76db7776fe2e757027b02f586a8c2817057bc0613fa5852183cbfd"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('nlp': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
