{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./eztransfer_modelzoo'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为环境变量做好准备\n",
    "import os\n",
    "from io import StringIO\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_text = \"\"\"\n",
    "HOME=./eztransfer_modelzoo\n",
    "\"\"\"\n",
    "\n",
    "load_dotenv(stream=StringIO(env_text), override=True, verbose=True)\n",
    "os.environ.get(\"HOME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:\\\\code\\\\github\\\\EasyTransfer',\n",
       " 'd:\\\\code\\\\github\\\\EasyTransfer\\\\examples',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles\\\\vscode_datascience_helpers',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles',\n",
       " 'c:\\\\Users\\\\tzh\\\\.vscode\\\\extensions\\\\ms-toolsai.jupyter-2021.11.1001550889\\\\pythonFiles\\\\lib\\\\python',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\python39.zip',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\DLLs',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2',\n",
       " '',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Anaconda3\\\\envs\\\\tf2\\\\lib\\\\site-packages\\\\Pythonwin']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 让本地的 easytransfer 的优先级更高\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*********** tf.__version__ is 2.7.0 ******\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入 easytransfer, 并验证, 因为原始的没有 __version__ 这个参数\n",
    "import importlib\n",
    "import easytransfer as easytransfer\n",
    "importlib.reload(easytransfer)\n",
    "easytransfer.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ipykernel_launcher', '--ip=127.0.0.1', '--stdin=9013', '--control=9011', '--hb=9010', '--Session.signature_scheme=\"hmac-sha256\"', '--Session.key=b\"31e13c8e-643d-4d19-8f16-f699e073ed32\"', '--shell=9012', '--transport=\"tcp\"', '--iopub=9014', '--f=C:\\\\Users\\\\tzh\\\\AppData\\\\Local\\\\Temp\\\\tmp-31956J0lyvtO0GPAo.json']\n"
     ]
    }
   ],
   "source": [
    "# jupyter 特殊操作\n",
    "old_argv = sys.argv\n",
    "print(old_argv)\n",
    "sys.argv = old_argv[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\tzh\\AppData\\Local\\Temp\\ipykernel_26792\\943327746.py:12: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from easytransfer import Config, base_model, layers, model_zoo, preprocessors\n",
    "from easytransfer.datasets import CSVReader, CSVWriter\n",
    "from easytransfer.evaluators import classification_eval_metrics\n",
    "from easytransfer.losses import softmax_cross_entropy\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(32)\n",
    "\n",
    "print(tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassification(base_model):\n",
    "    \"\"\"\n",
    "    定义文本分类模型\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TextClassification, self).__init__(**kwargs)\n",
    "        self.user_defined_config = kwargs[\"user_defined_config\"]\n",
    "\n",
    "    def build_logits(self, features, mode=None):\n",
    "        \"\"\"构图\n",
    "\n",
    "        Args:\n",
    "            features ([type]): [description]\n",
    "            mode ([type], optional): [description]. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        # 负责对原始数据进行预处理，生成模型需要的特征，比如：input_ids, input_mask, segment_ids等\n",
    "        preprocessor = preprocessors.get_preprocessor(\n",
    "            self.pretrain_model_name_or_path, user_defined_config=self.user_defined_config\n",
    "        )\n",
    "        # 负责构建网络的backbone\n",
    "        model = model_zoo.get_pretrained_model(self.pretrain_model_name_or_path)\n",
    "\n",
    "        dense = layers.Dense(self.num_labels, kernel_initializer=layers.get_initializer(0.02), name=\"dense\")\n",
    "        input_ids, input_mask, segment_ids, label_ids = preprocessor(features)\n",
    "        _, pooled_output = model([input_ids, input_mask, segment_ids], mode=mode)\n",
    "        logits = dense(pooled_output)\n",
    "\n",
    "        # 用于 continue finetune\n",
    "        # self.check_and_init_from_checkpoint(mode)\n",
    "        return logits, label_ids\n",
    "\n",
    "    def build_loss(self, logits, labels):\n",
    "        \"\"\"定义损失函数\n",
    "\n",
    "        Args:\n",
    "            logits ([type]): logits returned from build_logits\n",
    "            labels ([type]): labels returned from build_logits\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        return softmax_cross_entropy(labels, self.num_labels, logits)\n",
    "\n",
    "    def build_eval_metrics(self, logits, labels):\n",
    "        \"\"\"定义评估指标\n",
    "\n",
    "        Args:\n",
    "            logits ([type]): logits returned from build_logits\n",
    "            labels ([type]): labels returned from build_logits\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        return classification_eval_metrics(logits, labels, self.num_labels)\n",
    "\n",
    "    def build_predictions(self, output):\n",
    "        \"\"\"定义预测输出\n",
    "\n",
    "        Args:\n",
    "            output ([type]): returned from build_logits\n",
    "\n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "        logits, _ = output\n",
    "        predictions = dict()\n",
    "        index = tf.argmax(logits, axis=-1, output_type=tf.int32)\n",
    "        predictions[\"predict_index\"] = index\n",
    "        predictions[\"predict_softmax\"] = tf.nn.softmax(logits)\n",
    "        # 核心是理解 shape, 最后一维才是类别数量, 第一个维度是 batch_size\n",
    "        predictions[\"predict_prob\"] = tf.gather(tf.nn.softmax(logits), index, axis=-1)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config_json):\n",
    "    config = Config(mode=\"train_and_evaluate_on_the_fly\", config_json=config_json)\n",
    "    app = TextClassification(user_defined_config=config)\n",
    "\n",
    "    train_reader = CSVReader(\n",
    "        input_glob=app.train_input_fp, is_training=True, input_schema=app.input_schema, batch_size=app.train_batch_size,\n",
    "    )\n",
    "    eval_reader = CSVReader(\n",
    "        input_glob=app.eval_input_fp, is_training=False, input_schema=app.input_schema, batch_size=app.eval_batch_size,\n",
    "    )\n",
    "\n",
    "    app.run_train_and_evaluate(train_reader=train_reader, eval_reader=eval_reader)\n",
    "\n",
    "\n",
    "def predict(config_json):\n",
    "    config = Config(mode=\"predict_on_the_fly\", config_json=config_json)\n",
    "    app = TextClassification(user_defined_config=config)\n",
    "\n",
    "    pred_reader = CSVReader(\n",
    "        input_glob=app.predict_input_fp,\n",
    "        is_training=False,\n",
    "        input_schema=app.input_schema,\n",
    "        batch_size=app.predict_batch_size,\n",
    "    )\n",
    "    pred_writer = CSVWriter(output_glob=app.predict_output_fp, output_schema=app.output_schema)\n",
    "\n",
    "    result = app.run_predict(reader=pred_reader, writer=None, checkpoint_path=app.predict_checkpoint_path)\n",
    "    for row in result:\n",
    "        print(row)\n",
    "        break\n",
    "\n",
    "\n",
    "def evaluate(config_json):\n",
    "    config = Config(mode=\"evaluate_on_the_fly\", config_json=config_json)\n",
    "    app = TextClassification(user_defined_config=config)\n",
    "\n",
    "    eval_reader = CSVReader(\n",
    "        input_glob=app.eval_input_fp, is_training=False, input_schema=app.input_schema, batch_size=app.eval_batch_size,\n",
    "    )\n",
    "\n",
    "    result = app.run_evaluate(reader=eval_reader, checkpoint_path=app.eval_ckpt_path)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:***************** modelZooBasePath ./eztransfer_modelzoo\\.eztransfer_modelzoo ***************\n",
      "INFO:tensorflow:total number of training examples 1000\n",
      "INFO:tensorflow:***********Running in train_and_evaluate_on_the_fly mode***********\n",
      "INFO:tensorflow:***********Disable Tao***********\n",
      "INFO:tensorflow:***********NCCL_IB_DISABLE 0***********\n",
      "INFO:tensorflow:***********NCCL_P2P_DISABLE 0***********\n",
      "INFO:tensorflow:***********NCCL_SHM_DISABLE 0***********\n",
      "INFO:tensorflow:***********NCCL_MAX_NRINGS 4***********\n",
      "INFO:tensorflow:***********NCCL_MIN_NRINGS 2***********\n",
      "INFO:tensorflow:***********NCCL_LAUNCH_MODE PARALLEL***********\n",
      "INFO:tensorflow:***********TF_JIT_PROFILING False***********\n",
      "INFO:tensorflow:***********PAI_ENABLE_HLO_DUMPER False***********\n",
      "INFO:tensorflow:***********Single worker, Single gpu, Don't use distribution strategy***********\n",
      "INFO:tensorflow:model_dir: model_dir_tf2_test\n",
      "INFO:tensorflow:num workers: 1\n",
      "INFO:tensorflow:num gpus: 1\n",
      "INFO:tensorflow:learning rate: 1e-05\n",
      "INFO:tensorflow:train batch size: 32\n",
      "INFO:tensorflow:global batch size: 32\n",
      "INFO:tensorflow:num accumulated batches: 1\n",
      "INFO:tensorflow:num model replica: 1\n",
      "INFO:tensorflow:num train examples per epoch: 1000\n",
      "INFO:tensorflow:num epochs: 5.0\n",
      "INFO:tensorflow:train steps: 157\n",
      "INFO:tensorflow:save steps: 31\n",
      "INFO:tensorflow:throttle secs: 100\n",
      "INFO:tensorflow:keep checkpoint max: 1\n",
      "INFO:tensorflow:warmup ratio: 0.1\n",
      "INFO:tensorflow:gradient clip: True\n",
      "INFO:tensorflow:clip norm value: 1.0\n",
      "INFO:tensorflow:log step count steps: 100\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'model_dir_tf2_test', '_tf_random_seed': 123123, '_save_summary_steps': 100, '_save_checkpoints_steps': 31, '_save_checkpoints_secs': None, '_session_config': intra_op_parallelism_threads: 1024\n",
      "inter_op_parallelism_threads: 1024\n",
      "gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "  allow_growth: true\n",
      "  force_gpu_compatible: true\n",
      "}\n",
      "allow_soft_placement: true\n",
      ", '_keep_checkpoint_max': 1, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function EzTransEstimator._build_model_fn.<locals>.model_fn at 0x000001C6834CA040>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:num eval steps: None\n",
      "INFO:tensorflow:num_parallel_batches 1\n",
      "INFO:tensorflow:shuffle_buffer_size None\n",
      "INFO:tensorflow:prefetch_buffer_size 1\n",
      "INFO:tensorflow:batch_size 32\n",
      "INFO:tensorflow:distribution_strategy None\n",
      "INFO:tensorflow:num_micro_batches 1\n",
      "INFO:tensorflow:input_schema label:str:1,content:str:1\n",
      "INFO:tensorflow:D:/code/py_nlp_classify/data/small/train.csv, total number of training examples 1000\n",
      "INFO:tensorflow:num_parallel_batches 1\n",
      "INFO:tensorflow:shuffle_buffer_size None\n",
      "INFO:tensorflow:prefetch_buffer_size 1\n",
      "INFO:tensorflow:batch_size 8\n",
      "INFO:tensorflow:distribution_strategy None\n",
      "INFO:tensorflow:num_micro_batches 1\n",
      "INFO:tensorflow:input_schema label:str:1,content:str:1\n",
      "INFO:tensorflow:D:/code/py_nlp_classify/data/small/dev.csv, total number of eval examples 100\n",
      "INFO:tensorflow:*********Calling tf.estimator.train_and_evaluate *********\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 31 or save_checkpoints_secs None.\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\training_util.py:400: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Random shuffle on the whole 1000 training examples\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From d:\\code\\github\\EasyTransfer\\easytransfer\\layers\\utils.py:102: The name tf.keras.initializers.TruncatedNormal is deprecated. Please use tf.compat.v1.keras.initializers.TruncatedNormal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\keras\\initializers\\initializers_v1.py:408: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "input_shape [1, 512]\n",
      "INFO:tensorflow:从文件中还原预训练模型\n",
      "INFO:tensorflow:tvars: [<tf.Variable 'bert_pre_trained_model/bert/embeddings/word_embeddings:0' shape=(21128, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/position_embeddings:0' shape=(512, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/token_type_embeddings:0' shape=(2, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/embeddings/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_0/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_1/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_2/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_3/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_4/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_5/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_6/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_7/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_8/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_9/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_10/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/self/query/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/self/query/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/self/key/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/self/key/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/self/value/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/self/value/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/output/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/attention/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/intermediate/dense/kernel:0' shape=(768, 3072) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/intermediate/dense/bias:0' shape=(3072,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/output/dense/kernel:0' shape=(3072, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/output/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/output/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/encoder/layer_11/output/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/pooler/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/bert/pooler/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/cls/predictions/output_bias:0' shape=(21128,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/cls/predictions/transform/dense/kernel:0' shape=(768, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/cls/predictions/transform/dense/bias:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/transform/LayerNorm/beta:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/transform/LayerNorm/gamma:0' shape=(768,) dtype=float32>, <tf.Variable 'bert_pre_trained_model/cls/seq_relationship/output_weights:0' shape=(2, 768) dtype=float32>, <tf.Variable 'bert_pre_trained_model/cls/seq_relationship/output_bias:0' shape=(2,) dtype=float32>]\n",
      "Variable: cls/predictions/transform/LayerNorm/beta in ckpt not in trainable variable\n",
      "Variable: cls/predictions/transform/LayerNorm/gamma in ckpt not in trainable variable\n",
      "INFO:tensorflow:Load weights from D:/code/py_nlp_classify/model/bert/google-bert-base-zh/bert_model.ckpt\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:465: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1096: calling string_split (from tensorflow.python.ops.ragged.ragged_string_ops) with delimiter is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "delimiter is deprecated, please use sep instead.\n",
      "input_shape [<tf.Tensor 'bert_pre_trained_model/bert/strided_slice_1:0' shape=() dtype=int32>, 64]\n",
      "INFO:tensorflow:*******Warmup 15 steps***********\n",
      "INFO:tensorflow:*******Using adam optimizer************\n",
      "INFO:tensorflow:*******Num of trainable variables 102893977************\n",
      "INFO:tensorflow:*******Clip Gradients************\n",
      "INFO:tensorflow:*******Clip Norm Value 1.0*********\n",
      "INFO:tensorflow:*********Num towers is 1 *********\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_dir_tf2_test\\model.ckpt-0\n",
      "WARNING:tensorflow:From C:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1165: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m config_json \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_config_tf2_test.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_json\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(config_json)\u001b[0m\n\u001b[0;32m      5\u001b[0m train_reader \u001b[38;5;241m=\u001b[39m CSVReader(\n\u001b[0;32m      6\u001b[0m     input_glob\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39mtrain_input_fp, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, input_schema\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39minput_schema, batch_size\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39mtrain_batch_size,\n\u001b[0;32m      7\u001b[0m )\n\u001b[0;32m      8\u001b[0m eval_reader \u001b[38;5;241m=\u001b[39m CSVReader(\n\u001b[0;32m      9\u001b[0m     input_glob\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39meval_input_fp, is_training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_schema\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39minput_schema, batch_size\u001b[38;5;241m=\u001b[39mapp\u001b[38;5;241m.\u001b[39meval_batch_size,\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 12\u001b[0m \u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_train_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_reader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_reader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_reader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_reader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\code\\github\\EasyTransfer\\easytransfer\\engines\\model.py:1121\u001b[0m, in \u001b[0;36mEzTransEstimator.run_train_and_evaluate\u001b[1;34m(self, train_reader, eval_reader)\u001b[0m\n\u001b[0;32m   1113\u001b[0m eval_spec \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mEvalSpec(\n\u001b[0;32m   1114\u001b[0m     input_fn\u001b[38;5;241m=\u001b[39meval_reader\u001b[38;5;241m.\u001b[39mget_input_fn(),\n\u001b[0;32m   1115\u001b[0m     steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_eval_steps,\n\u001b[0;32m   1116\u001b[0m     \u001b[38;5;66;03m# 评估最小间隔时间\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m     throttle_secs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthrottle_secs,\n\u001b[0;32m   1118\u001b[0m )\n\u001b[0;32m   1120\u001b[0m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*********Calling tf.estimator.train_and_evaluate *********\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1121\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_spec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py:504\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[1;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[0;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (config\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m==\u001b[39m run_config_lib\u001b[38;5;241m.\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mEVALUATOR \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    499\u001b[0m     config\u001b[38;5;241m.\u001b[39mtask_id \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    500\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    501\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFor distributed training, there can only be one `evaluator` task \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    502\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(with task id 0).  Given task id \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(config\u001b[38;5;241m.\u001b[39mtask_id))\n\u001b[1;32m--> 504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py:645\u001b[0m, in \u001b[0;36m_TrainingExecutor.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mcluster_spec \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     config\u001b[38;5;241m.\u001b[39mtask_type \u001b[38;5;241m!=\u001b[39m run_config_lib\u001b[38;5;241m.\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mEVALUATOR):\n\u001b[0;32m    643\u001b[0m   tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    644\u001b[0m       \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning training and evaluation locally (non-distributed).\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 645\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_local\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    647\u001b[0m \u001b[38;5;66;03m# Distributed case.\u001b[39;00m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39mtask_type:\n\u001b[0;32m    649\u001b[0m   \u001b[38;5;66;03m# TODO(xiejw): Improve the error message about how to set the TF_CONFIG\u001b[39;00m\n\u001b[0;32m    650\u001b[0m   \u001b[38;5;66;03m# correctly.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\training.py:742\u001b[0m, in \u001b[0;36m_TrainingExecutor.run_local\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    737\u001b[0m listener_for_eval \u001b[38;5;241m=\u001b[39m _NewCheckpointListenerForEvaluate(\n\u001b[0;32m    738\u001b[0m     evaluator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_spec\u001b[38;5;241m.\u001b[39mthrottle_secs,\n\u001b[0;32m    739\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_continuous_eval_listener)\n\u001b[0;32m    740\u001b[0m saving_listeners \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_spec\u001b[38;5;241m.\u001b[39msaving_listeners \u001b[38;5;241m+\u001b[39m (listener_for_eval,)\n\u001b[1;32m--> 742\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_hooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    748\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m listener_for_eval\u001b[38;5;241m.\u001b[39meval_result \u001b[38;5;129;01mor\u001b[39;00m _EvalResult(\n\u001b[0;32m    749\u001b[0m     status\u001b[38;5;241m=\u001b[39m_EvalStatus\u001b[38;5;241m.\u001b[39mMISSING_CHECKPOINT)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m eval_result\u001b[38;5;241m.\u001b[39mmetrics, listener_for_eval\u001b[38;5;241m.\u001b[39mexport_results\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:360\u001b[0m, in \u001b[0;36mEstimator.train\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    357\u001b[0m hooks\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_train_steps_to_hooks(steps, max_steps))\n\u001b[0;32m    359\u001b[0m saving_listeners \u001b[38;5;241m=\u001b[39m _check_listeners_type(saving_listeners)\n\u001b[1;32m--> 360\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss for final step: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, loss)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1186\u001b[0m, in \u001b[0;36mEstimator._train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_model_distributed(input_fn, hooks, saving_listeners)\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1186\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1217\u001b[0m, in \u001b[0;36mEstimator._train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1214\u001b[0m estimator_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_model_fn(features, labels, ModeKeys\u001b[38;5;241m.\u001b[39mTRAIN,\n\u001b[0;32m   1215\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig)\n\u001b[0;32m   1216\u001b[0m global_step_tensor \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mget_global_step(g)\n\u001b[1;32m-> 1217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_with_estimator_spec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_hooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1218\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[43m                                       \u001b[49m\u001b[43msaving_listeners\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py:1512\u001b[0m, in \u001b[0;36mEstimator._train_with_estimator_spec\u001b[1;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mlog_step_count_steps \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mlog_step_count_steps \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m   1507\u001b[0m       worker_hooks\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m   1508\u001b[0m           tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mStepCounterHook(\n\u001b[0;32m   1509\u001b[0m               every_n_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mlog_step_count_steps,\n\u001b[0;32m   1510\u001b[0m               output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mmodel_dir))\n\u001b[1;32m-> 1512\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMonitoredTrainingSession\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaster\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_chief\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_chief\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaffold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaffold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker_hooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchief_only_hooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchief_hooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[0;32m   1519\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mestimator_spec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_chief_hooks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1520\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_checkpoint_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Saving is handled by a hook.\u001b[39;49;00m\n\u001b[0;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_summaries_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_summary_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_wait_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_creation_timeout_secs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_step_count_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_step_count_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_graph_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheckpoint_save_graph_def\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m mon_sess:\n\u001b[0;32m   1526\u001b[0m   loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1527\u001b[0m   current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:613\u001b[0m, in \u001b[0;36mMonitoredTrainingSession\u001b[1;34m(master, is_chief, checkpoint_dir, scaffold, hooks, chief_only_hooks, save_checkpoint_secs, save_summaries_steps, save_summaries_secs, config, stop_grace_period_secs, log_step_count_steps, max_wait_secs, save_checkpoint_steps, summary_dir, save_graph_def)\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hooks:\n\u001b[0;32m    612\u001b[0m   all_hooks\u001b[38;5;241m.\u001b[39mextend(hooks)\n\u001b[1;32m--> 613\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMonitoredSession\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    614\u001b[0m \u001b[43m    \u001b[49m\u001b[43msession_creator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    615\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhooks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_hooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop_grace_period_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_grace_period_secs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1058\u001b[0m, in \u001b[0;36mMonitoredSession.__init__\u001b[1;34m(self, session_creator, hooks, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1055\u001b[0m              session_creator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1056\u001b[0m              hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1057\u001b[0m              stop_grace_period_secs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m120\u001b[39m):\n\u001b[1;32m-> 1058\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMonitoredSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1059\u001b[0m \u001b[43m      \u001b[49m\u001b[43msession_creator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[43m      \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1061\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshould_recover\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1062\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstop_grace_period_secs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop_grace_period_secs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:761\u001b[0m, in \u001b[0;36m_MonitoredSession.__init__\u001b[1;34m(self, session_creator, hooks, should_recover, stop_grace_period_secs)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinated_creator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CoordinatedSessionCreator(\n\u001b[0;32m    757\u001b[0m     session_creator\u001b[38;5;241m=\u001b[39msession_creator \u001b[38;5;129;01mor\u001b[39;00m ChiefSessionCreator(),\n\u001b[0;32m    758\u001b[0m     hooks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks,\n\u001b[0;32m    759\u001b[0m     stop_grace_period_secs\u001b[38;5;241m=\u001b[39mstop_grace_period_secs)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_recover:\n\u001b[1;32m--> 761\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess \u001b[38;5;241m=\u001b[39m \u001b[43m_RecoverableSession\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_coordinated_creator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    763\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinated_creator\u001b[38;5;241m.\u001b[39mcreate_session()\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1267\u001b[0m, in \u001b[0;36m_RecoverableSession.__init__\u001b[1;34m(self, sess_creator)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;124;03m\"\"\"Create a new `_RecoverableSession`.\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03mThe value returned by calling `sess_creator.create_session()` will be the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;124;03m  sess_creator: A 'SessionCreator' to be wrapped by recoverable.\u001b[39;00m\n\u001b[0;32m   1265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sess_creator \u001b[38;5;241m=\u001b[39m sess_creator\n\u001b[1;32m-> 1267\u001b[0m _WrappedSession\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:1272\u001b[0m, in \u001b[0;36m_RecoverableSession._create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m   1271\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess_creator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1273\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _PREEMPTION_ERRORS \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1274\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m   1275\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn error was raised while a session was being created. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1276\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThis may be due to a preemption of a connected worker \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1281\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mincreasing the number of parameter servers assigned to \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1282\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe job. Error: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m, e)\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\monitored_session.py:921\u001b[0m, in \u001b[0;36m_MonitoredSession._CoordinatedSessionCreator.create_session\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[38;5;66;03m# Inform the hooks that a new session has been created.\u001b[39;00m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks:\n\u001b[1;32m--> 921\u001b[0m   \u001b[43mhook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_create_session\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_sess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoord\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _CoordinatedSession(\n\u001b[0;32m    923\u001b[0m     _HookedSession(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtf_sess, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hooks), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord,\n\u001b[0;32m    924\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop_grace_period_secs)\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py:601\u001b[0m, in \u001b[0;36mCheckpointSaverHook.after_create_session\u001b[1;34m(self, session, coord)\u001b[0m\n\u001b[0;32m    598\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m meta_graph\u001b[38;5;241m.\u001b[39mcreate_meta_graph_def(\n\u001b[0;32m    599\u001b[0m     graph_def\u001b[38;5;241m=\u001b[39mgraph\u001b[38;5;241m.\u001b[39mas_graph_def(add_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), saver_def\u001b[38;5;241m=\u001b[39msaver_def)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_writer\u001b[38;5;241m.\u001b[39madd_graph(graph)\n\u001b[1;32m--> 601\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summary_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;66;03m# The checkpoint saved here is the state at step \"global_step\".\u001b[39;00m\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save(session, global_step)\n",
      "File \u001b[1;32mC:\\Anaconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py:248\u001b[0m, in \u001b[0;36mSummaryToEventTransformer.add_meta_graph\u001b[1;34m(self, meta_graph_def, global_step)\u001b[0m\n\u001b[0;32m    245\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta_graph_def must be type MetaGraphDef, saw type: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    246\u001b[0m                   \u001b[38;5;28mtype\u001b[39m(meta_graph_def))\n\u001b[0;32m    247\u001b[0m meta_graph_bytes \u001b[38;5;241m=\u001b[39m meta_graph_def\u001b[38;5;241m.\u001b[39mSerializeToString()\n\u001b[1;32m--> 248\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mevent_pb2\u001b[49m\u001b[38;5;241m.\u001b[39mEvent(meta_graph_def\u001b[38;5;241m=\u001b[39mmeta_graph_bytes)\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_event(event, global_step)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "config_json = json.load(open(\"user_config_tf2_test.json\", \"r\", encoding=\"utf-8\"))\n",
    "train(config_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_json[\"evaluate_config\"][\"eval_checkpoint_path\"] = config_json[\"evaluate_config\"][\"eval_checkpoint_path\"].format(157)\n",
    "evaluate(config_json)\n",
    "# {'loss': 2.0560822, 'py_accuracy': 0.42, 'py_macro_f1': 0.33929557, 'py_micro_f1': 0.42, 'py_weighted_f1': 0.38653803, 'global_step': 157}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c369c7a0bd18095d69cc6bcfdfaf93c8e305f9651a20b05d28ea042855c27d0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('tf2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
